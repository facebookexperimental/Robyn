{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robyn: Marketing Mix Modeling Application\n",
    "\n",
    "This notebook demonstrates the usage of Robyn, a Marketing Mix Modeling (MMM) application. \n",
    "We'll go through the main steps of performing robyn_inputs and robyn_engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Required Libraries. Define Paths.\n",
    "\n",
    "First, be sure to setup your virtual environment. Be sure to switch over to your new environment in this notebook. \n",
    "\n",
    "-```cd {root_folder}```\n",
    "\n",
    "-```python3 -m yourvenv```\n",
    "\n",
    "-```source yourvenv/bin/activate```\n",
    "\n",
    "-```cd Robyn/python```\n",
    "\n",
    "-```pip install -r requirements.txt```\n",
    "\n",
    "\n",
    "Then import the necessary libraries. Make sure to define your paths below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add Robyn to path\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "from typing import Dict\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.data.entities.enums import AdstockType\n",
    "from robyn.data.entities.holidays_data import HolidaysData\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters\n",
    "from robyn.modeling.entities.modelrun_trials_config import TrialsConfig\n",
    "from robyn.modeling.model_executor import ModelExecutor\n",
    "from robyn.modeling.entities.enums import NevergradAlgorithm, Models\n",
    "from robyn.modeling.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Mock R data\n",
    "\n",
    "We need to set the base path for the data directory.\n",
    "Create a .env file in the same directory as your notebook and put in define the path to the data dir.\n",
    "for example: ROBYN_BASE_PATH=.../Robyn/R/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the simulated data and holidays data\n",
    "dt_simulated_weekly = pd.read_csv(\"resources/dt_simulated_weekly.csv\")\n",
    "\n",
    "dt_prophet_holidays = pd.read_csv(\"resources/dt_prophet_holidays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MMM Data\n",
    "\n",
    "We will now set up the MMM data specification which includes defining the dependent variable, independent variables, and the time window for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>revenue</th>\n",
       "      <th>tv_S</th>\n",
       "      <th>ooh_S</th>\n",
       "      <th>print_S</th>\n",
       "      <th>facebook_I</th>\n",
       "      <th>search_clicks_P</th>\n",
       "      <th>search_S</th>\n",
       "      <th>competitor_sales_B</th>\n",
       "      <th>facebook_S</th>\n",
       "      <th>events</th>\n",
       "      <th>newsletter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>2.754372e+06</td>\n",
       "      <td>22358.346667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12728.488889</td>\n",
       "      <td>2.430128e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8125009</td>\n",
       "      <td>7607.132915</td>\n",
       "      <td>na</td>\n",
       "      <td>19401.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2.584277e+06</td>\n",
       "      <td>28613.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.527033e+06</td>\n",
       "      <td>9837.238486</td>\n",
       "      <td>4133.333333</td>\n",
       "      <td>7901549</td>\n",
       "      <td>1141.952450</td>\n",
       "      <td>na</td>\n",
       "      <td>14791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>2.547387e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132278.4</td>\n",
       "      <td>453.866667</td>\n",
       "      <td>1.665159e+07</td>\n",
       "      <td>12044.119653</td>\n",
       "      <td>3786.666667</td>\n",
       "      <td>8300197</td>\n",
       "      <td>4256.375378</td>\n",
       "      <td>na</td>\n",
       "      <td>14544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>2.875220e+06</td>\n",
       "      <td>83450.306667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17680.000000</td>\n",
       "      <td>1.054977e+07</td>\n",
       "      <td>12268.070319</td>\n",
       "      <td>4253.333333</td>\n",
       "      <td>8122883</td>\n",
       "      <td>2800.490677</td>\n",
       "      <td>na</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2.215953e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.934090e+06</td>\n",
       "      <td>9467.248023</td>\n",
       "      <td>3613.333333</td>\n",
       "      <td>7105985</td>\n",
       "      <td>689.582605</td>\n",
       "      <td>na</td>\n",
       "      <td>15478.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE       revenue          tv_S     ooh_S       print_S  \\\n",
       "0  2015-11-23  2.754372e+06  22358.346667       0.0  12728.488889   \n",
       "1  2015-11-30  2.584277e+06  28613.453333       0.0      0.000000   \n",
       "2  2015-12-07  2.547387e+06      0.000000  132278.4    453.866667   \n",
       "3  2015-12-14  2.875220e+06  83450.306667       0.0  17680.000000   \n",
       "4  2015-12-21  2.215953e+06      0.000000  277336.0      0.000000   \n",
       "\n",
       "     facebook_I  search_clicks_P     search_S  competitor_sales_B  \\\n",
       "0  2.430128e+07         0.000000     0.000000             8125009   \n",
       "1  5.527033e+06      9837.238486  4133.333333             7901549   \n",
       "2  1.665159e+07     12044.119653  3786.666667             8300197   \n",
       "3  1.054977e+07     12268.070319  4253.333333             8122883   \n",
       "4  2.934090e+06      9467.248023  3613.333333             7105985   \n",
       "\n",
       "    facebook_S events    newsletter  \n",
       "0  7607.132915     na  19401.653846  \n",
       "1  1141.952450     na  14791.000000  \n",
       "2  4256.375378     na  14544.000000  \n",
       "3  2800.490677     na   2800.000000  \n",
       "4   689.582605     na  15478.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_mmm_data(dt_simulated_weekly) -> MMMData:\n",
    "\n",
    "    mmm_data_spec = MMMData.MMMDataSpec(\n",
    "        dep_var=\"revenue\",\n",
    "        dep_var_type=\"revenue\",\n",
    "        date_var=\"DATE\",\n",
    "        context_vars=[\"competitor_sales_B\", \"events\"],\n",
    "        paid_media_spends=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"],\n",
    "        paid_media_vars=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"],\n",
    "        organic_vars=[\"newsletter\"],\n",
    "        window_start=\"2016-01-01\",\n",
    "        window_end=\"2018-12-31\",\n",
    "    )\n",
    "\n",
    "    return MMMData(data=dt_simulated_weekly, mmmdata_spec=mmm_data_spec)\n",
    "\n",
    "\n",
    "mmm_data = setup_mmm_data(dt_simulated_weekly)\n",
    "mmm_data.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preprocessing\n",
    "\n",
    "We will perform feature engineering to prepare the data for modeling. This includes transformations like adstock and other preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters setup complete.\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = Hyperparameters(\n",
    "    {\n",
    "        \"facebook_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"print_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"tv_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.3, 0.8],\n",
    "        ),\n",
    "        \"search_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"ooh_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"newsletter\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "    },\n",
    "    adstock=AdstockType.GEOMETRIC,\n",
    "    lambda_=0.0,\n",
    "    train_size=[0.5, 0.8],\n",
    ")\n",
    "\n",
    "print(\"Hyperparameters setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HolidaysData object\n",
    "holidays_data = HolidaysData(\n",
    "    dt_holidays=dt_prophet_holidays,\n",
    "    prophet_vars=[\"trend\", \"season\", \"holiday\"],\n",
    "    prophet_country=\"DE\",\n",
    "    prophet_signs=[\"default\", \"default\", \"default\"],\n",
    ")\n",
    "# Setup FeaturizedMMMData\n",
    "feature_engineering = FeatureEngineering(mmm_data, hyperparameters, holidays_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 03:52:10 - robyn.modeling.feature_engineering - INFO - Starting feature engineering process\n",
      "2024-11-13 03:52:10 - robyn.modeling.feature_engineering - INFO - Starting Prophet decomposition\n",
      "2024-11-13 03:52:10 - robyn.modeling.feature_engineering - INFO - Starting Prophet decomposition\n",
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/prophet/forecaster.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.holidays['ds'] = pd.to_datetime(self.holidays['ds'])\n",
      "03:52:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2024-11-13 03:52:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "03:52:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2024-11-13 03:52:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Prophet decomposition complete\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Starting model runs for paid media variables with different exposure metrics\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Fitting spend-exposure model for facebook_I\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Fitting spend-exposure model for search_clicks_P\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Completed model runs for 2 channels\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Feature engineering complete\n",
      "/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/modeling/feature_engineering.py:82: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dt_mod = dt_mod.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "2024-11-13 03:52:11 - robyn.modeling.feature_engineering - INFO - Filled 0 missing values\n"
     ]
    }
   ],
   "source": [
    "featurized_mmm_data = feature_engineering.perform_feature_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - INFO - Initializing FeaturePlotter\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - INFO - Generating spend-exposure plot for channel: tv_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Channel tv_S not found in featurized data results\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Failed to generate spend-exposure plot for channel tv_S: No spend-exposure data available for channel: tv_S\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/visualization/feature_visualization.py\", line 88, in plot_spend_exposure\n",
      "    raise ValueError(f\"No spend-exposure data available for channel: {channel}\")\n",
      "ValueError: No spend-exposure data available for channel: tv_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - INFO - Generating spend-exposure plot for channel: ooh_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Channel ooh_S not found in featurized data results\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Failed to generate spend-exposure plot for channel ooh_S: No spend-exposure data available for channel: ooh_S\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/visualization/feature_visualization.py\", line 88, in plot_spend_exposure\n",
      "    raise ValueError(f\"No spend-exposure data available for channel: {channel}\")\n",
      "ValueError: No spend-exposure data available for channel: ooh_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - INFO - Generating spend-exposure plot for channel: print_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Channel print_S not found in featurized data results\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Failed to generate spend-exposure plot for channel print_S: No spend-exposure data available for channel: print_S\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/visualization/feature_visualization.py\", line 88, in plot_spend_exposure\n",
      "    raise ValueError(f\"No spend-exposure data available for channel: {channel}\")\n",
      "ValueError: No spend-exposure data available for channel: print_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - INFO - Generating spend-exposure plot for channel: facebook_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Channel facebook_S not found in featurized data results\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Failed to generate spend-exposure plot for channel facebook_S: No spend-exposure data available for channel: facebook_S\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/visualization/feature_visualization.py\", line 88, in plot_spend_exposure\n",
      "    raise ValueError(f\"No spend-exposure data available for channel: {channel}\")\n",
      "ValueError: No spend-exposure data available for channel: facebook_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - INFO - Generating spend-exposure plot for channel: search_S\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Channel search_S not found in featurized data results\n",
      "2024-11-13 03:52:11 - robyn.visualization.feature_visualization - ERROR - Failed to generate spend-exposure plot for channel search_S: No spend-exposure data available for channel: search_S\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/visualization/feature_visualization.py\", line 88, in plot_spend_exposure\n",
      "    raise ValueError(f\"No spend-exposure data available for channel: {channel}\")\n",
      "ValueError: No spend-exposure data available for channel: search_S\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping tv_S: No spend-exposure data available for channel: tv_S\n",
      "Skipping ooh_S: No spend-exposure data available for channel: ooh_S\n",
      "Skipping print_S: No spend-exposure data available for channel: print_S\n",
      "Skipping facebook_S: No spend-exposure data available for channel: facebook_S\n",
      "Skipping search_S: No spend-exposure data available for channel: search_S\n"
     ]
    }
   ],
   "source": [
    "from robyn.visualization.feature_visualization import FeaturePlotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a FeaturePlotter instance\n",
    "feature_plotter = FeaturePlotter(mmm_data, hyperparameters)\n",
    "\n",
    "# Plot spend-exposure relationship for each channel\n",
    "for channel in mmm_data.mmmdata_spec.paid_media_spends:\n",
    "    try:\n",
    "        fig = feature_plotter.plot_spend_exposure(featurized_mmm_data, channel)\n",
    "        plt.show()\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping {channel}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 03:52:11 - robyn.modeling.base_model_executor - INFO - Initializing BaseModelExecutor\n",
      "2024-11-13 03:52:11 - robyn.modeling.model_executor - INFO - Starting model execution with model_name=Models.RIDGE\n",
      "2024-11-13 03:52:11 - robyn.modeling.base_model_executor - INFO - Input validation successful\n",
      "2024-11-13 03:52:11 - robyn.modeling.base_model_executor - INFO - Preparing hyperparameters\n",
      "2024-11-13 03:52:11 - robyn.modeling.base_model_executor - INFO - Completed hyperparameter preparation with 19 parameters to optimize\n",
      "2024-11-13 03:52:11 - robyn.modeling.model_executor - INFO - Initializing Ridge model builder\n",
      "2024-11-13 03:52:11 - robyn.modeling.model_executor - INFO - Building models with configured parameters\n",
      "2024-11-13 03:52:11 - robyn.modeling.ridge_model_builder - INFO - Collecting hyperparameters for optimization... {'prepared_hyperparameters': Hyperparameters(hyperparameters={'facebook_S': ChannelHyperparameters(thetas=[0, 0.3], shapes=None, scales=None, alphas=[0.5, 3], gammas=[0.3, 1], penalty=None), 'print_S': ChannelHyperparameters(thetas=[0.1, 0.4], shapes=None, scales=None, alphas=[0.5, 3], gammas=[0.3, 1], penalty=None), 'tv_S': ChannelHyperparameters(thetas=[0.3, 0.8], shapes=None, scales=None, alphas=[0.5, 3], gammas=[0.3, 1], penalty=None), 'search_S': ChannelHyperparameters(thetas=[0, 0.3], shapes=None, scales=None, alphas=[0.5, 3], gammas=[0.3, 1], penalty=None), 'ooh_S': ChannelHyperparameters(thetas=[0.1, 0.4], shapes=None, scales=None, alphas=[0.5, 3], gammas=[0.3, 1], penalty=None), 'newsletter': ChannelHyperparameters(thetas=[0.1, 0.4], shapes=None, scales=None, alphas=[0.5, 3], gammas=[0.3, 1], penalty=None)}, adstock=<AdstockType.GEOMETRIC: 'geometric'>, lambda_=0.0, train_size=[0.5, 0.8], hyper_bound_list_updated={}), 'hyper_to_optimize': {'facebook_S_thetas': [0, 0.3], 'facebook_S_alphas': [0.5, 3], 'facebook_S_gammas': [0.3, 1], 'print_S_thetas': [0.1, 0.4], 'print_S_alphas': [0.5, 3], 'print_S_gammas': [0.3, 1], 'tv_S_thetas': [0.3, 0.8], 'tv_S_alphas': [0.5, 3], 'tv_S_gammas': [0.3, 1], 'search_S_thetas': [0, 0.3], 'search_S_alphas': [0.5, 3], 'search_S_gammas': [0.3, 1], 'ooh_S_thetas': [0.1, 0.4], 'ooh_S_alphas': [0.5, 3], 'ooh_S_gammas': [0.3, 1], 'newsletter_thetas': [0.1, 0.4], 'newsletter_alphas': [0.5, 3], 'newsletter_gammas': [0.3, 1], 'train_size': [0.5, 0.8]}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Starting 5 trials with 2000 iterations each using TwoPointsDE nevergrad algorithm on x cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running trial 1 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-13 03:54:06 - robyn.modeling.ridge_model_builder - INFO -  Finished in 1.92 mins\n",
      "Running trial 2 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-13 03:56:04 - robyn.modeling.ridge_model_builder - INFO -  Finished in 1.96 mins\n",
      "Running trial 3 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-13 03:58:03 - robyn.modeling.ridge_model_builder - INFO -  Finished in 1.95 mins\n",
      "Running trial 4 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-13 04:00:00 - robyn.modeling.ridge_model_builder - INFO -  Finished in 1.94 mins\n",
      "Running trial 5 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-13 04:01:57 - robyn.modeling.ridge_model_builder - INFO -  Finished in 1.94 mins\n",
      "2024-11-13 04:01:58 - robyn.visualization.model_convergence_visualizer - INFO - Initialized ModelConvergenceVisualizer with n_cuts=20, nrmse_win=[0, 0.998]\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - INFO - Starting convergence calculation\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - WARNING - 'mape' column not found or all zeros. Assuming model is not calibrated.\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - INFO - Convergence status for DECOMP.RSSD: converged\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - INFO - DECOMP.RSSD converged: sd@qt.20 16316.603 <= 46763.906 & |med@qt.20| 87396.98 <= 239675.85\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - WARNING - Convergence status for NRMSE: NOT converged\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - INFO - NRMSE NOT converged: sd@qt.20 0.000 <= 0.001 & |med@qt.20| 0.06 > 0.05\n",
      "2024-11-13 04:01:58 - robyn.modeling.convergence.convergence - INFO - Convergence calculation completed successfully\n",
      "2024-11-13 04:01:58 - robyn.modeling.model_executor - INFO - Model building completed successfully\n",
      "2024-11-13 04:01:58 - robyn.modeling.model_executor - INFO - Model execution completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Setup ModelExecutor\n",
    "model_executor = ModelExecutor(\n",
    "    mmmdata=mmm_data,\n",
    "    holidays_data=holidays_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    calibration_input=None,  # Add calibration input if available\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    ")\n",
    "\n",
    "# Setup TrialsConfig\n",
    "trials_config = TrialsConfig(iterations=2000, trials=5)  # Set to the number of cores you want to use\n",
    "\n",
    "print(\n",
    "    f\">>> Starting {trials_config.trials} trials with {trials_config.iterations} iterations each using {NevergradAlgorithm.TWO_POINTS_DE.value} nevergrad algorithm on x cores...\"\n",
    ")\n",
    "\n",
    "# Run the model\n",
    "\n",
    "output_models = model_executor.model_run(\n",
    "    trials_config=trials_config,\n",
    "    ts_validation=False,  # changed from True to False -> deacitvate\n",
    "    add_penalty_factor=False,\n",
    "    rssd_zero_penalty=True,\n",
    "    cores=8,\n",
    "    nevergrad_algo=NevergradAlgorithm.TWO_POINTS_DE,\n",
    "    intercept=True,\n",
    "    intercept_sign=\"non_negative\",\n",
    "    model_name=Models.RIDGE,\n",
    ")\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# TODO fix graph outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decomp_rssd: Shape = ()\n",
      "decomp_spend_dist: Shape = (10000, 34)\n",
      "elapsed: No shape attribute, Type = float\n",
      "elapsed_accum: No shape attribute, Type = float\n",
      "iter_ng: No shape attribute, Type = int\n",
      "iter_par: No shape attribute, Type = int\n",
      "lambda_: No shape attribute, Type = float\n",
      "lambda_hp: No shape attribute, Type = float\n",
      "lambda_max: Shape = ()\n",
      "lambda_min_ratio: No shape attribute, Type = float\n",
      "lift_calibration: No shape attribute, Type = NoneType\n",
      "mape: No shape attribute, Type = float\n",
      "nrmse: Shape = ()\n",
      "pos: No shape attribute, Type = bool\n",
      "result_hyp_param: Shape = (2000, 34)\n",
      "rsq_test: No shape attribute, Type = float\n",
      "rsq_train: No shape attribute, Type = float\n",
      "rsq_val: No shape attribute, Type = float\n",
      "sol_id: No shape attribute, Type = str\n",
      "train_size: No shape attribute, Type = float\n",
      "trial: No shape attribute, Type = int\n",
      "x_decomp_agg: Shape = (24000, 29)\n"
     ]
    }
   ],
   "source": [
    "# Assuming model_outputs.trials[0] is already an object from your model\n",
    "trial = output_models.trials[0]\n",
    "\n",
    "\n",
    "# Function to check if an object has a 'shape' attribute\n",
    "def has_shape(obj):\n",
    "    return hasattr(obj, \"shape\")\n",
    "\n",
    "\n",
    "# Get all attribute names of the object and print their shapes if they have a 'shape' attribute\n",
    "attribute_names = [attr for attr in dir(trial) if not callable(getattr(trial, attr)) and not attr.startswith(\"__\")]\n",
    "for attribute_name in attribute_names:\n",
    "    attribute_value = getattr(trial, attribute_name)\n",
    "    if has_shape(attribute_value):\n",
    "        print(f\"{attribute_name}: Shape = {attribute_value.shape}\")\n",
    "    else:\n",
    "        print(f\"{attribute_name}: No shape attribute, Type = {type(attribute_value).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decomp_rssd: Shape = ()\n",
      "decomp_spend_dist: Shape = (10000, 34)\n",
      "  Columns: Index(['rn', 'coef', 'xDecompAgg', 'xDecompPerc', 'xDecompMeanNon0',\n",
      "       'xDecompMeanNon0Perc', 'xDecompAggRF', 'xDecompPercRF',\n",
      "       'xDecompMeanNon0RF', 'xDecompMeanNon0PercRF', 'pos', 'mean_spend',\n",
      "       'total_spend', 'spend_share', 'spend_share_refresh', 'effect_share',\n",
      "       'effect_share_refresh', 'rsq_train', 'rsq_val', 'rsq_test',\n",
      "       'nrmse_train', 'nrmse_val', 'nrmse_test', 'nrmse', 'decomp.rssd',\n",
      "       'mape', 'lambda', 'lambda_hp', 'lambda_max', 'lambda_min_ratio',\n",
      "       'solID', 'trial', 'iterNG', 'iterPar'],\n",
      "      dtype='object')\n",
      "elapsed: No shape attribute, Type = float\n",
      "elapsed_accum: No shape attribute, Type = float\n",
      "iter_ng: No shape attribute, Type = int\n",
      "iter_par: No shape attribute, Type = int\n",
      "lambda_: No shape attribute, Type = float\n",
      "lambda_hp: No shape attribute, Type = float\n",
      "lambda_max: Shape = ()\n",
      "lambda_min_ratio: No shape attribute, Type = float\n",
      "lift_calibration: No shape attribute, Type = NoneType\n",
      "mape: No shape attribute, Type = float\n",
      "nrmse: Shape = ()\n",
      "pos: No shape attribute, Type = bool\n",
      "result_hyp_param: Shape = (2000, 34)\n",
      "  Columns: Index(['facebook_S_thetas', 'facebook_S_alphas', 'facebook_S_gammas',\n",
      "       'print_S_thetas', 'print_S_alphas', 'print_S_gammas', 'tv_S_thetas',\n",
      "       'tv_S_alphas', 'tv_S_gammas', 'search_S_thetas', 'search_S_alphas',\n",
      "       'search_S_gammas', 'ooh_S_thetas', 'ooh_S_alphas', 'ooh_S_gammas',\n",
      "       'newsletter_thetas', 'newsletter_alphas', 'newsletter_gammas',\n",
      "       'train_size', 'rsq_train', 'rsq_val', 'rsq_test', 'nrmse_train',\n",
      "       'nrmse_val', 'nrmse_test', 'nrmse', 'decomp.rssd', 'mape', 'lambda',\n",
      "       'solID', 'trial', 'iterNG', 'iterPar', 'ElapsedAccum'],\n",
      "      dtype='object')\n",
      "rsq_test: No shape attribute, Type = float\n",
      "rsq_train: No shape attribute, Type = float\n",
      "rsq_val: No shape attribute, Type = float\n",
      "sol_id: No shape attribute, Type = str\n",
      "train_size: No shape attribute, Type = float\n",
      "trial: No shape attribute, Type = int\n",
      "x_decomp_agg: Shape = (24000, 29)\n",
      "  Columns: Index(['rn', 'coef', 'xDecompAgg', 'xDecompPerc', 'xDecompMeanNon0',\n",
      "       'xDecompMeanNon0Perc', 'xDecompAggRF', 'xDecompPercRF',\n",
      "       'xDecompMeanNon0RF', 'xDecompMeanNon0PercRF', 'pos', 'train_size',\n",
      "       'rsq_train', 'rsq_val', 'rsq_test', 'nrmse_train', 'nrmse_val',\n",
      "       'nrmse_test', 'nrmse', 'decomp.rssd', 'mape', 'lambda', 'lambda_hp',\n",
      "       'lambda_max', 'lambda_min_ratio', 'solID', 'trial', 'iterNG',\n",
      "       'iterPar'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Assuming model_outputs.trials[0] is already an object from your model\n",
    "trial = output_models.trials[0]\n",
    "\n",
    "\n",
    "# Function to check if an object has a 'shape' attribute\n",
    "def has_shape(obj):\n",
    "    return hasattr(obj, \"shape\")\n",
    "\n",
    "\n",
    "# Get all attribute names of the object and print their shapes if they have a 'shape' attribute\n",
    "attribute_names = [attr for attr in dir(trial) if not callable(getattr(trial, attr)) and not attr.startswith(\"__\")]\n",
    "for attribute_name in attribute_names:\n",
    "    attribute_value = getattr(trial, attribute_name)\n",
    "    if has_shape(attribute_value):\n",
    "        print(f\"{attribute_name}: Shape = {attribute_value.shape}\")\n",
    "        # Check if the attribute is a multi-dimensional array with more than one column\n",
    "        if len(attribute_value.shape) > 1 and attribute_value.shape[1] > 1:\n",
    "            try:\n",
    "                # Attempt to print column names if it's a structured array or DataFrame\n",
    "                columns = (\n",
    "                    attribute_value.columns if hasattr(attribute_value, \"columns\") else attribute_value.dtype.names\n",
    "                )\n",
    "                print(f\"  Columns: {columns}\")\n",
    "            except AttributeError:\n",
    "                print(\"  No column names available.\")\n",
    "    else:\n",
    "        print(f\"{attribute_name}: No shape attribute, Type = {type(attribute_value).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model ID: 2_1962_1\n"
     ]
    }
   ],
   "source": [
    "best_model_id = output_models.select_id\n",
    "print(f\"Best model ID: {best_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument should be a bytes-like object or ASCII string, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoo_distrb_plot\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output_models\u001b[38;5;241m.\u001b[39mconvergence:\n\u001b[1;32m     10\u001b[0m     moo_distrb_plot \u001b[38;5;241m=\u001b[39m output_models\u001b[38;5;241m.\u001b[39mconvergence[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoo_distrb_plot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m     display(Image(data\u001b[38;5;241m=\u001b[39m\u001b[43mbase64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb64decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmoo_distrb_plot\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/base64.py:80\u001b[0m, in \u001b[0;36mb64decode\u001b[0;34m(s, altchars, validate)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mb64decode\u001b[39m(s, altchars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode the Base64 encoded bytes-like object or ASCII string s.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    Optional altchars must be a bytes-like object or ASCII string of length 2\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    in the input result in a binascii.Error.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43m_bytes_from_decode_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m altchars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m         altchars \u001b[38;5;241m=\u001b[39m _bytes_from_decode_data(altchars)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/base64.py:45\u001b[0m, in \u001b[0;36m_bytes_from_decode_data\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(s)\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument should be a bytes-like object or ASCII \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring, not \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m s\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument should be a bytes-like object or ASCII string, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1. Display the MOO Distribution Plot\n",
    "if \"moo_distrb_plot\" in output_models.convergence:\n",
    "    moo_distrb_plot = output_models.convergence[\"moo_distrb_plot\"]\n",
    "    display(Image(data=base64.b64decode(moo_distrb_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Display the MOO Cloud Plot\n",
    "if \"moo_cloud_plot\" in output_models.convergence:\n",
    "    moo_cloud_plot = output_models.convergence[\"moo_cloud_plot\"]\n",
    "    display(Image(data=base64.b64decode(moo_cloud_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Print convergence messages\n",
    "if \"conv_msg\" in output_models.convergence:\n",
    "    for msg in output_models.convergence[\"conv_msg\"]:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Display time series validation and convergence plots\n",
    "if \"ts_validation_plot\" in output_models.convergence:\n",
    "    ts_validation_plot = output_models.convergence[\"ts_validation_plot\"]\n",
    "    display(Image(data=base64.b64decode(ts_validation_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_id = output_models.select_id\n",
    "print(f\"Best model ID: {best_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_mapper import load_data_from_json, import_input_collect, import_output_models\n",
    "\n",
    "# Load data from JSON exported from R\n",
    "raw_input_collect = load_data_from_json(\n",
    "    \"/Users/yijuilee/project_robyn/original/Robyn_original_2/Robyn/robyn_api/data/Pareto_InputCollect.json\"\n",
    ")\n",
    "raw_output_models = load_data_from_json(\n",
    "    \"/Users/yijuilee/project_robyn/original/Robyn_original_2/Robyn/robyn_api/data/Pareto_OutputModels.json\"\n",
    ")\n",
    "\n",
    "# Convert R data to Python objects\n",
    "r_input_collect = import_input_collect(raw_input_collect)\n",
    "r_output_models = import_output_models(raw_output_models)\n",
    "\n",
    "# Extract individual components\n",
    "r_mmm_data = r_input_collect[\"mmm_data\"]\n",
    "r_featurized_mmm_data = r_input_collect[\"featurized_mmm_data\"]\n",
    "r_holidays_data = r_input_collect[\"holidays_data\"]\n",
    "r_hyperparameters = r_input_collect[\"hyperparameters\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
