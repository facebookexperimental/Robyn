{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f2f84a",
   "metadata": {},
   "source": [
    "# Robyn: Marketing Mix Modeling Application\n",
    "\n",
    "This notebook demonstrates the usage of Robyn, a Marketing Mix Modeling (MMM) application. \n",
    "We'll go through the main steps of performing robyn_inputs and robyn_engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd474b7",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Required Libraries. Define Paths.\n",
    "\n",
    "First, be sure to setup your virtual environment. Be sure to switch over to your new environment in this notebook. \n",
    "\n",
    "-```cd {root_folder}```\n",
    "\n",
    "-```python3 -m yourvenv```\n",
    "\n",
    "-```source yourvenv/bin/activate```\n",
    "\n",
    "-```cd Robyn/python```\n",
    "\n",
    "-```pip install -r requirements.txt```\n",
    "\n",
    "\n",
    "Then import the necessary libraries. Make sure to define your paths below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5930e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add Robyn to path\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8146e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 14:38:19,624 - robyn - INFO - Logging is set up to console only.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "from typing import Dict\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.data.entities.enums import AdstockType\n",
    "from robyn.data.entities.holidays_data import HolidaysData\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters\n",
    "from robyn.modeling.entities.modelrun_trials_config import TrialsConfig\n",
    "from robyn.modeling.model_executor import ModelExecutor\n",
    "from robyn.modeling.entities.enums import NevergradAlgorithm, Models\n",
    "from robyn.modeling.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442024b2",
   "metadata": {},
   "source": [
    "## 2.1 Load Mock R data\n",
    "\n",
    "We need to set the base path for the data directory.\n",
    "Create a .env file in the same directory as your notebook and put in define the path to the data dir.\n",
    "for example: ROBYN_BASE_PATH=.../Robyn/R/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the simulated data and holidays data\n",
    "dt_simulated_weekly = pd.read_csv(\"resources/dt_simulated_weekly.csv\")\n",
    "\n",
    "dt_prophet_holidays = pd.read_csv(\"resources/dt_prophet_holidays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0c5ac",
   "metadata": {},
   "source": [
    "## Setup MMM Data\n",
    "\n",
    "We will now set up the MMM data specification which includes defining the dependent variable, independent variables, and the time window for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mmm_data(dt_simulated_weekly) -> MMMData:\n",
    "\n",
    "    mmm_data_spec = MMMData.MMMDataSpec(\n",
    "        dep_var=\"revenue\",\n",
    "        dep_var_type=\"revenue\",\n",
    "        date_var=\"DATE\",\n",
    "        context_vars=[\"competitor_sales_B\", \"events\"],\n",
    "        paid_media_spends=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"],\n",
    "        paid_media_vars=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"],\n",
    "        organic_vars=[\"newsletter\"],\n",
    "        window_start=\"2016-01-01\",\n",
    "        window_end=\"2018-12-31\",\n",
    "        factor_vars=[\"events\"],\n",
    "    )\n",
    "\n",
    "    return MMMData(data=dt_simulated_weekly, mmmdata_spec=mmm_data_spec)\n",
    "\n",
    "\n",
    "mmm_data = setup_mmm_data(dt_simulated_weekly)\n",
    "mmm_data.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fa54e",
   "metadata": {},
   "source": [
    "## Feature Preprocessing\n",
    "\n",
    "We will perform feature engineering to prepare the data for modeling. This includes transformations like adstock and other preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = Hyperparameters(\n",
    "    {\n",
    "        \"facebook_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"print_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"tv_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.3, 0.8],\n",
    "        ),\n",
    "        \"search_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"ooh_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"newsletter\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "    },\n",
    "    adstock=AdstockType.GEOMETRIC,\n",
    "    lambda_=0.0,\n",
    "    train_size=[0.5, 0.8],\n",
    ")\n",
    "\n",
    "print(\"Hyperparameters setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HolidaysData object\n",
    "holidays_data = HolidaysData(\n",
    "    dt_holidays=dt_prophet_holidays,\n",
    "    prophet_vars=[\"trend\", \"season\", \"holiday\"],\n",
    "    prophet_country=\"DE\",\n",
    "    prophet_signs=[\"default\", \"default\", \"default\"],\n",
    ")\n",
    "# Setup FeaturizedMMMData\n",
    "feature_engineering = FeatureEngineering(mmm_data, hyperparameters, holidays_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup FeaturizedMMMData\n",
    "featurized_mmm_data = feature_engineering.perform_feature_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be81245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.visualization.feature_visualization import FeaturePlotter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a FeaturePlotter instance\n",
    "feature_plotter = FeaturePlotter(mmm_data, hyperparameters)\n",
    "# Extract the list of results\n",
    "results_list = featurized_mmm_data.modNLS[\"results\"]\n",
    "# Plot spend-exposure relationship for each channel in the results\n",
    "for result in results_list:\n",
    "    channel = result[\"channel\"]\n",
    "    try:\n",
    "        fig = feature_plotter.plot_spend_exposure(featurized_mmm_data, channel)\n",
    "        plt.show()\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping {channel}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b864e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_mapper import load_data_from_json, import_input_collect\n",
    "\n",
    "# Load data from JSON exported from R\n",
    "raw_input_collect = load_data_from_json(\n",
    "    \"/Users/yijuilee/project_robyn/original/Robyn_original_2/Robyn/robyn_api/data/Feature_InputCollect.json\"\n",
    ")\n",
    "\n",
    "# Convert R data to Python objects\n",
    "r_input_collect = import_input_collect(raw_input_collect)\n",
    "\n",
    "# Extract individual components\n",
    "r_mmm_data = r_input_collect[\"mmm_data\"]\n",
    "r_featurized_mmm_data = r_input_collect[\"featurized_mmm_data\"]\n",
    "r_holidays_data = r_input_collect[\"holidays_data\"]\n",
    "r_hyperparameters = r_input_collect[\"hyperparameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featurized_mmm_data.dt_mod[\"events\"].unique())\n",
    "\n",
    "print(r_featurized_mmm_data.dt_mod[\"events\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695db7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming featurized_mmm_data and r_featurized_mmm_data are your DataFrames\n",
    "# and they have been defined and populated with data\n",
    "# Calculate descriptive statistics for both DataFrames\n",
    "python_stats = featurized_mmm_data.dt_mod[[\"trend\", \"season\", \"holiday\", \"events\"]].describe()\n",
    "r_stats = r_featurized_mmm_data.dt_mod[[\"trend\", \"season\", \"holiday\", \"events\"]].describe()\n",
    "print(python_stats)\n",
    "print(r_stats)\n",
    "# Define a tolerance level for comparison\n",
    "tolerance = 1000\n",
    "\n",
    "\n",
    "# Function to compare two DataFrames\n",
    "def compare_stats(python_stats: pd.DataFrame, r_stats: pd.DataFrame, tolerance: float):\n",
    "    # Iterate over each column and statistic\n",
    "    for column in python_stats.columns:\n",
    "        for stat in python_stats.index:\n",
    "            python_value = python_stats.loc[stat, column]\n",
    "            r_value = r_stats.loc[stat, column]\n",
    "            # Assert that the values are within the specified tolerance\n",
    "            assert abs(python_value - r_value) <= tolerance, (\n",
    "                f\"Difference in {stat} for {column} exceeds tolerance: \"\n",
    "                f\"Python value = {python_value}, R value = {r_value}\"\n",
    "            )\n",
    "\n",
    "\n",
    "# Compare the statistics\n",
    "compare_stats(python_stats, r_stats, tolerance)\n",
    "print(\"All statistics are within the specified tolerance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featurized_mmm_data.dt_modRollWind[\"events\"].unique())\n",
    "\n",
    "print(r_featurized_mmm_data.dt_modRollWind[\"events\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27318df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'yhat' lists to DataFrames for comparison\n",
    "yhat1_df = pd.DataFrame(featurized_mmm_data.modNLS[\"yhat\"])\n",
    "yhat2_df = pd.DataFrame(r_featurized_mmm_data.modNLS[\"yhat\"])\n",
    "\n",
    "# Print the shape and a quick preview of 'yhat' DataFrames\n",
    "print(\"Shape of 'yhat' from modNLS1:\", yhat1_df.shape)\n",
    "print(\"Preview of 'yhat' from modNLS1:\")\n",
    "print(yhat1_df.head())\n",
    "\n",
    "print(\"\\nShape of 'yhat' from modNLS2:\", yhat2_df.shape)\n",
    "print(\"Preview of 'yhat' from modNLS2:\")\n",
    "print(yhat2_df.head())\n",
    "\n",
    "# Describe the numeric columns to compare distributions\n",
    "print(\"\\nDescription of 'yhat' from modNLS1:\")\n",
    "print(yhat1_df.describe())\n",
    "\n",
    "print(\"\\nDescription of 'yhat' from modNLS2:\")\n",
    "print(yhat2_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compare_modNLS(modNLS1, modNLS2, tolerance=1e-1, percent_tolerance=5):\n",
    "    # Print available channels for debugging\n",
    "    channels1 = [result[\"channel\"] for result in modNLS1[\"results\"]]\n",
    "    channels2 = [result[\"channel\"] for result in modNLS2[\"results\"]]\n",
    "    print(\"Channels in modNLS1:\", channels1)\n",
    "    print(\"Channels in modNLS2:\", channels2)\n",
    "\n",
    "    # Print the structure of 'results' for debugging\n",
    "    print(\"\\nStructure of 'results' in modNLS1:\")\n",
    "    for result in modNLS1[\"results\"]:\n",
    "        print(result)\n",
    "\n",
    "    print(\"\\nStructure of 'results' in modNLS2:\")\n",
    "    for result in modNLS2[\"results\"]:\n",
    "        print(result)\n",
    "\n",
    "    # Compare 'results' section\n",
    "    for result1 in modNLS1[\"results\"]:\n",
    "        channel = result1[\"channel\"]\n",
    "        result2 = next((r for r in modNLS2[\"results\"] if r[\"channel\"] == channel), None)\n",
    "        assert result2 is not None, f\"Channel {channel} not found in second modNLS\"\n",
    "\n",
    "        # Compare R-squared values separately\n",
    "        assert np.isclose(\n",
    "            result1[\"rsq_nls\"], result2[\"rsq_nls\"], atol=tolerance\n",
    "        ), f\"R-squared (NLS) mismatch for {channel}: {result1['rsq_nls']} vs {result2['rsq_nls']}\"\n",
    "\n",
    "        assert np.isclose(\n",
    "            result1[\"rsq_lm\"], result2[\"rsq_lm\"], atol=tolerance\n",
    "        ), f\"R-squared (LM) mismatch for {channel}: {result1['rsq_lm']} vs {result2['rsq_lm']}\"\n",
    "\n",
    "        # Compare coefficients\n",
    "        for coef_key in [\"Vmax\", \"Km\", \"coef_lm\"]:\n",
    "            coef_value1 = result1.get(coef_key)\n",
    "            coef_value2 = result2.get(coef_key)\n",
    "            assert coef_value2 is not None, f\"Coefficient {coef_key} not found for {channel}\"\n",
    "            assert np.isclose(\n",
    "                coef_value1, coef_value2, atol=tolerance\n",
    "            ), f\"Coefficient {coef_key} mismatch for {channel}: {coef_value1} vs {coef_value2}\"\n",
    "\n",
    "    # Convert 'yhat' lists to DataFrames for comparison\n",
    "    yhat1_df = pd.DataFrame(modNLS1[\"yhat\"]).sort_values(by=[\"ds\", \"channel\"]).reset_index(drop=True)\n",
    "    yhat2_df = pd.DataFrame(modNLS2[\"yhat\"]).sort_values(by=[\"ds\", \"channel\"]).reset_index(drop=True)\n",
    "\n",
    "    # Print preview of 'yhat' DataFrames\n",
    "    print(\"Preview of 'yhat' from modNLS1:\")\n",
    "    print(yhat1_df.head())\n",
    "    print(\"\\nPreview of 'yhat' from modNLS2:\")\n",
    "    print(yhat2_df.head())\n",
    "\n",
    "    # Compare 'yhat' DataFrame\n",
    "    assert yhat1_df.shape == yhat2_df.shape, \"Shape mismatch in 'yhat' DataFrame\"\n",
    "\n",
    "    # Select only numeric columns for comparison\n",
    "    numeric_cols = yhat1_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Use describe to get summary statistics\n",
    "    desc1 = yhat1_df[numeric_cols].describe()\n",
    "    desc2 = yhat2_df[numeric_cols].describe()\n",
    "\n",
    "    # Compare each statistic separately\n",
    "    for stat in desc1.index:\n",
    "        for col in numeric_cols:\n",
    "            val1 = desc1.at[stat, col]\n",
    "            val2 = desc2.at[stat, col]\n",
    "            if not np.isclose(val1, val2, rtol=percent_tolerance):\n",
    "                print(f\"Mismatch in {stat} of column '{col}': {val1} vs {val2}\")\n",
    "                raise AssertionError(f\"Mismatch in {stat} of column '{col}'\")\n",
    "\n",
    "    print(\"All comparisons passed within the specified tolerance.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "compare_modNLS(featurized_mmm_data.modNLS, r_featurized_mmm_data.modNLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(featurized_mmm_data.modNLS.keys())\n",
    "\n",
    "for key in featurized_mmm_data.modNLS:\n",
    "    print(f\"\\nKey: {key}\")\n",
    "    print(f\"Type: {type(featurized_mmm_data.modNLS[key])}\")\n",
    "    if isinstance(featurized_mmm_data.modNLS[key], list):\n",
    "        print(f\"Number of items: {len(featurized_mmm_data.modNLS[key])}\")\n",
    "        if len(featurized_mmm_data.modNLS[key]) > 0:\n",
    "            print(\"Sample item:\", featurized_mmm_data.modNLS[key][0])\n",
    "    elif isinstance(featurized_mmm_data.modNLS[key], dict):\n",
    "        print(\"Sample keys:\", list(featurized_mmm_data.modNLS[key].keys()))\n",
    "        if len(featurized_mmm_data.modNLS[key]) > 0:\n",
    "            first_key = next(iter(featurized_mmm_data.modNLS[key]))\n",
    "            print(\"Sample item:\", featurized_mmm_data.modNLS[key][first_key])\n",
    "    else:\n",
    "        print(\"Value:\", featurized_mmm_data.modNLS[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name = \"facebook_S\"  # Example channel name\n",
    "results = featurized_mmm_data.modNLS.get(\"results\", [])\n",
    "channel_data = next((item for item in results if item[\"channel\"] == channel_name), None)\n",
    "if channel_data:\n",
    "    print(f\"\\nData for channel {channel_name}:\")\n",
    "    print(channel_data)\n",
    "else:\n",
    "    print(f\"No data found for channel {channel_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
