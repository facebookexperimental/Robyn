{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robyn: Marketing Mix Modeling Application\n",
    "\n",
    "This notebook demonstrates the usage of Robyn, a Marketing Mix Modeling (MMM) application. \n",
    "We'll go through the main steps of performing robyn_inputs and robyn_engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Required Libraries. Define Paths.\n",
    "\n",
    "First, be sure to setup your virtual environment. Be sure to switch over to your new environment in this notebook. \n",
    "\n",
    "-```cd {root_folder}```\n",
    "\n",
    "-```python3 -m yourvenv```\n",
    "\n",
    "-```source yourvenv/bin/activate```\n",
    "\n",
    "-```cd Robyn/python```\n",
    "\n",
    "-```pip install -r requirements.txt```\n",
    "\n",
    "\n",
    "Then import the necessary libraries. Make sure to define your paths below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add Robyn to path\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.data.entities.enums import AdstockType\n",
    "from robyn.data.entities.holidays_data import HolidaysData\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters\n",
    "from robyn.modeling.entities.modelrun_trials_config import TrialsConfig\n",
    "from robyn.modeling.model_executor import ModelExecutor\n",
    "from robyn.modeling.entities.enums import NevergradAlgorithm, Models\n",
    "from robyn.modeling.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Mock R data\n",
    "\n",
    "We need to set the base path for the data directory.\n",
    "Create a .env file in the same directory as your notebook and put in define the path to the data dir.\n",
    "for example: ROBYN_BASE_PATH=.../Robyn/R/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the simulated data and holidays data\n",
    "dt_simulated_weekly = pd.read_csv(\"resources/dt_simulated_weekly.csv\")\n",
    "\n",
    "dt_prophet_holidays = pd.read_csv(\"resources/dt_prophet_holidays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MMM Data\n",
    "\n",
    "We will now set up the MMM data specification which includes defining the dependent variable, independent variables, and the time window for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>revenue</th>\n",
       "      <th>tv_S</th>\n",
       "      <th>ooh_S</th>\n",
       "      <th>print_S</th>\n",
       "      <th>facebook_I</th>\n",
       "      <th>search_clicks_P</th>\n",
       "      <th>search_S</th>\n",
       "      <th>competitor_sales_B</th>\n",
       "      <th>facebook_S</th>\n",
       "      <th>events</th>\n",
       "      <th>newsletter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>2.754372e+06</td>\n",
       "      <td>22358.346667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12728.488889</td>\n",
       "      <td>2.430128e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8125009</td>\n",
       "      <td>7607.132915</td>\n",
       "      <td>na</td>\n",
       "      <td>19401.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2.584277e+06</td>\n",
       "      <td>28613.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.527033e+06</td>\n",
       "      <td>9837.238486</td>\n",
       "      <td>4133.333333</td>\n",
       "      <td>7901549</td>\n",
       "      <td>1141.952450</td>\n",
       "      <td>na</td>\n",
       "      <td>14791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>2.547387e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132278.4</td>\n",
       "      <td>453.866667</td>\n",
       "      <td>1.665159e+07</td>\n",
       "      <td>12044.119653</td>\n",
       "      <td>3786.666667</td>\n",
       "      <td>8300197</td>\n",
       "      <td>4256.375378</td>\n",
       "      <td>na</td>\n",
       "      <td>14544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>2.875220e+06</td>\n",
       "      <td>83450.306667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17680.000000</td>\n",
       "      <td>1.054977e+07</td>\n",
       "      <td>12268.070319</td>\n",
       "      <td>4253.333333</td>\n",
       "      <td>8122883</td>\n",
       "      <td>2800.490677</td>\n",
       "      <td>na</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2.215953e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.934090e+06</td>\n",
       "      <td>9467.248023</td>\n",
       "      <td>3613.333333</td>\n",
       "      <td>7105985</td>\n",
       "      <td>689.582605</td>\n",
       "      <td>na</td>\n",
       "      <td>15478.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE       revenue          tv_S     ooh_S       print_S  \\\n",
       "0  2015-11-23  2.754372e+06  22358.346667       0.0  12728.488889   \n",
       "1  2015-11-30  2.584277e+06  28613.453333       0.0      0.000000   \n",
       "2  2015-12-07  2.547387e+06      0.000000  132278.4    453.866667   \n",
       "3  2015-12-14  2.875220e+06  83450.306667       0.0  17680.000000   \n",
       "4  2015-12-21  2.215953e+06      0.000000  277336.0      0.000000   \n",
       "\n",
       "     facebook_I  search_clicks_P     search_S  competitor_sales_B  \\\n",
       "0  2.430128e+07         0.000000     0.000000             8125009   \n",
       "1  5.527033e+06      9837.238486  4133.333333             7901549   \n",
       "2  1.665159e+07     12044.119653  3786.666667             8300197   \n",
       "3  1.054977e+07     12268.070319  4253.333333             8122883   \n",
       "4  2.934090e+06      9467.248023  3613.333333             7105985   \n",
       "\n",
       "    facebook_S events    newsletter  \n",
       "0  7607.132915     na  19401.653846  \n",
       "1  1141.952450     na  14791.000000  \n",
       "2  4256.375378     na  14544.000000  \n",
       "3  2800.490677     na   2800.000000  \n",
       "4   689.582605     na  15478.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_mmm_data(dt_simulated_weekly) -> MMMData:\n",
    "\n",
    "    mmm_data_spec = MMMData.MMMDataSpec(\n",
    "        dep_var=\"revenue\",\n",
    "        dep_var_type=\"revenue\",\n",
    "        date_var=\"DATE\",\n",
    "        context_vars=[\"competitor_sales_B\", \"events\"],\n",
    "        paid_media_spends=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"],\n",
    "        paid_media_vars=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"],\n",
    "        organic_vars=[\"newsletter\"],\n",
    "        window_start=\"2016-01-01\",\n",
    "        window_end=\"2018-12-31\",\n",
    "    )\n",
    "\n",
    "    return MMMData(data=dt_simulated_weekly, mmmdata_spec=mmm_data_spec)\n",
    "\n",
    "\n",
    "mmm_data = setup_mmm_data(dt_simulated_weekly)\n",
    "mmm_data.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preprocessing\n",
    "\n",
    "We will perform feature engineering to prepare the data for modeling. This includes transformations like adstock and other preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters setup complete.\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = Hyperparameters(\n",
    "    {\n",
    "        \"facebook_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"print_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"tv_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.3, 0.8],\n",
    "        ),\n",
    "        \"search_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"ooh_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"newsletter\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "    },\n",
    "    adstock=AdstockType.GEOMETRIC,\n",
    "    lambda_=[0, 1],\n",
    "    train_size=[0.5, 0.8],\n",
    ")\n",
    "\n",
    "print(\"Hyperparameters setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HolidaysData object\n",
    "holidays_data = HolidaysData(\n",
    "    dt_holidays=dt_prophet_holidays,\n",
    "    prophet_vars=[\"trend\", \"season\", \"holiday\"],\n",
    "    prophet_country=\"DE\",\n",
    "    prophet_signs=[\"default\", \"default\", \"default\"],\n",
    ")\n",
    "# Setup FeaturizedMMMData\n",
    "feature_engineering = FeatureEngineering(mmm_data, hyperparameters, holidays_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Starting feature engineering process\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Starting Prophet decomposition\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Starting Prophet decomposition\n",
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/prophet/forecaster.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.holidays['ds'] = pd.to_datetime(self.holidays['ds'])\n",
      "00:12:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2024-11-14 00:12:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:12:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2024-11-14 00:12:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Prophet decomposition complete\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Starting model runs for paid media variables with different exposure metrics\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Fitting spend-exposure model for facebook_I\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Fitting spend-exposure model for search_clicks_P\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Completed model runs for 2 channels\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Feature engineering complete\n",
      "/Users/yijuilee/robynpy_release_reviews/Robyn/python/src/robyn/modeling/feature_engineering.py:82: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dt_mod = dt_mod.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
      "2024-11-14 00:12:37 - robyn.modeling.feature_engineering - INFO - Filled 0 missing values\n"
     ]
    }
   ],
   "source": [
    "featurized_mmm_data = feature_engineering.perform_feature_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:12:37 - robyn.visualization.feature_visualization - INFO - Initializing FeaturePlotter\n"
     ]
    }
   ],
   "source": [
    "from robyn.visualization.feature_visualization import FeaturePlotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a FeaturePlotter instance\n",
    "feature_plotter = FeaturePlotter(mmm_data, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:12:37 - robyn.modeling.base_model_executor - INFO - Initializing BaseModelExecutor\n",
      "2024-11-14 00:12:37 - robyn.modeling.model_executor - INFO - Starting model execution with model_name=Models.RIDGE\n",
      "2024-11-14 00:12:37 - robyn.modeling.base_model_executor - INFO - Input validation successful\n",
      "2024-11-14 00:12:37 - robyn.modeling.base_model_executor - INFO - Preparing hyperparameters\n",
      "2024-11-14 00:12:37 - robyn.modeling.base_model_executor - INFO - Completed hyperparameter preparation with 20 parameters to optimize\n",
      "2024-11-14 00:12:37 - robyn.modeling.model_executor - INFO - Initializing Ridge model builder\n",
      "2024-11-14 00:12:37 - robyn.modeling.model_executor - INFO - Building models with configured parameters\n",
      "2024-11-14 00:12:37 - robyn.modeling.ridge_model_builder - INFO - Collecting hyperparameters for optimization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Starting 5 trials with 54 iterations each using TwoPointsDE nevergrad algorithm on...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running trial 1 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 00:12:41 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.05 mins\n",
      "Running trial 2 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 00:12:44 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.05 mins\n",
      "Running trial 3 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 00:12:47 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.05 mins\n",
      "Running trial 4 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 00:12:50 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.05 mins\n",
      "Running trial 5 of total 5 trials:  11%|███▉                               "
     ]
    }
   ],
   "source": [
    "# Setup ModelExecutor\n",
    "model_executor = ModelExecutor(\n",
    "    mmmdata=mmm_data,\n",
    "    holidays_data=holidays_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    calibration_input=None,  # Add calibration input if available\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    ")\n",
    "\n",
    "# Setup TrialsConfig\n",
    "trials_config = TrialsConfig(iterations=54, trials=5)  # Set to the number of cores you want to use\n",
    "\n",
    "print(\n",
    "    f\">>> Starting {trials_config.trials} trials with {trials_config.iterations} iterations each using {NevergradAlgorithm.TWO_POINTS_DE.value} nevergrad algorithm on...\"\n",
    ")\n",
    "\n",
    "# Run the model\n",
    "\n",
    "output_models = model_executor.model_run(\n",
    "    trials_config=trials_config,\n",
    "    ts_validation=True,  # changed from True to False -> deacitvate\n",
    "    add_penalty_factor=False,\n",
    "    rssd_zero_penalty=True,\n",
    "    cores=8,\n",
    "    nevergrad_algo=NevergradAlgorithm.TWO_POINTS_DE,\n",
    "    intercept=True,\n",
    "    intercept_sign=\"non_negative\",\n",
    "    model_name=Models.RIDGE,\n",
    ")\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_id = output_models.select_id\n",
    "print(f\"Best model ID: {best_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.modeling.entities.modeloutputs import ModelOutputs, Trial\n",
    "from robyn.modeling.pareto.pareto_optimizer import ParetoOptimizer\n",
    "from robyn.data.entities.enums import DependentVarType, PaidMediaSigns, OrganicSigns, ContextSigns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create ParetoOptimizer instance\n",
    "pareto_optimizer = ParetoOptimizer(mmm_data, output_models, hyperparameters, featurized_mmm_data, holidays_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run optimize function\n",
    "pareto_result = pareto_optimizer.optimize(pareto_fronts=\"auto\", min_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check results\n",
    "print(\"Pareto Optimization Results:\")\n",
    "print(f\"Number of Pareto fronts: {pareto_result.pareto_solutions}\")\n",
    "print(f\"MediaVecCollect: {pareto_result.media_vec_collect.shape, pareto_result.media_vec_collect}\")\n",
    "print(\"\\Hyper parameter solutions:\")\n",
    "print(pareto_result.result_hyp_param)\n",
    "\n",
    "print(\"\\nAggregated decomposition results:\")\n",
    "print(pareto_result.x_decomp_agg)\n",
    "print(\"\\result Calibration:\")\n",
    "print(pareto_result.result_calibration)\n",
    "print(\"\\nx Decomp Vec Collect:\")\n",
    "print(pareto_result.x_decomp_vec_collect.shape, pareto_result.x_decomp_vec_collect)\n",
    "print(\"\\nCarryover percentage all:\")\n",
    "print(pareto_result.df_caov_pct_all.shape, pareto_result.df_caov_pct_all)\n",
    "print(\"\\Plot Data Collected\")\n",
    "print(\"NUMBER OF PLOTS Data collected for:\", len(pareto_result.plot_data_collect))\n",
    "print(\"Plot data for solid 5_221_9\", pareto_result.plot_data_collect)\n",
    "\n",
    "# 6. Validate logic\n",
    "assert pareto_result.pareto_fronts == \"auto\" or isinstance(\n",
    "    pareto_result.pareto_fronts, int\n",
    "), \"Invalid pareto_fronts value\"\n",
    "assert not pareto_result.result_hyp_param.empty, \"Empty result_hyp_param DataFrame\"\n",
    "assert not pareto_result.x_decomp_agg.empty, \"Empty x_decomp_agg DataFrame\"\n",
    "\n",
    "print(\"\\nAll assertions passed. The optimize function is working as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pareto_result.pareto_solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Setup and Import\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Union, List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import necessary Robyn classes\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.modeling.entities.modeloutputs import ModelOutputs\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters\n",
    "from robyn.allocator.entities.enums import OptimizationScenario, ConstrMode\n",
    "from robyn.allocator.budget_allocator import BudgetAllocator\n",
    "from robyn.modeling.pareto.pareto_optimizer import ParetoResult\n",
    "from robyn.allocator.entities.allocation_config import AllocationConfig\n",
    "from robyn.allocator.entities.allocation_constraints import AllocationConstraints\n",
    "from robyn.visualization.allocator_plotter import AllocationPlotter\n",
    "from utils.data_mapper import load_data_from_json, import_input_collect, import_output_collect, import_output_models\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pareto_result.result_hyp_param[\"sol_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use the correct model ID from your pareto results\n",
    "available_models = pareto_result.result_hyp_param[\"sol_id\"].unique()  # or 'solID' if that's the column name\n",
    "print(f\"Available models: {available_models}\")\n",
    "# Initialize allocator with a valid model ID\n",
    "select_model = available_models[0]  # Use first available model\n",
    "\n",
    "# Initialize budget allocator\n",
    "allocator = BudgetAllocator(\n",
    "    mmm_data=mmm_data,\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    "    model_outputs=output_models,\n",
    "    pareto_result=pareto_result,  # Get ParetoResult from import_output_collect()\n",
    "    select_model=select_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Different Optimization Scenarios\n",
    "\n",
    "### Scenario 1: Default Max Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base constraints matching R example\n",
    "channel_constraints = AllocationConstraints(\n",
    "    channel_constr_low={\n",
    "        \"tv_S\": 0.7,  # -30% from base\n",
    "        \"ooh_S\": 0.7,\n",
    "        \"print_S\": 0.7,\n",
    "        \"facebook_S\": 0.7,\n",
    "        \"search_S\": 0.7,\n",
    "    },\n",
    "    channel_constr_up={\n",
    "        \"tv_S\": 1.2,  # +20% from base\n",
    "        \"ooh_S\": 1.5,  # +50% from base\n",
    "        \"print_S\": 1.5,\n",
    "        \"facebook_S\": 1.5,\n",
    "        \"search_S\": 1.5,\n",
    "    },\n",
    "    channel_constr_multiplier=3.0,\n",
    ")\n",
    "\n",
    "# Configure max response scenario\n",
    "max_response_config = AllocationConfig(\n",
    "    scenario=OptimizationScenario.MAX_RESPONSE,\n",
    "    constraints=channel_constraints,\n",
    "    date_range=\"last\",  # Use last period as initial\n",
    "    total_budget=None,  # Use historical budget\n",
    "    maxeval=100000,\n",
    "    optim_algo=\"SLSQP_AUGLAG\",\n",
    "    constr_mode=ConstrMode.EQUALITY,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "result = allocator.allocate(max_response_config)\n",
    "\n",
    "# Print results\n",
    "print(\n",
    "    f\"\"\"\n",
    "Model ID: {select_model}\n",
    "Scenario: {max_response_config.scenario}\n",
    "Use case: {result.metrics.get('use_case', '')}\n",
    "Window: {result.metrics.get('date_range_start')}:{result.metrics.get('date_range_end')} ({result.metrics.get('n_periods')} {mmm_data.mmmdata_spec.interval_type})\n",
    "\n",
    "Dep. Variable Type: {mmm_data.mmmdata_spec.dep_var_type}\n",
    "Media Skipped: {result.metrics.get('skipped_channels', 'None')}\n",
    "Relative Spend Increase: {result.metrics.get('spend_lift_pct', 0):.1f}% ({result.metrics.get('spend_lift_abs', 0):+.0f}K)\n",
    "Total Response Increase (Optimized): {result.metrics.get('response_lift', 0)*100:.1f}%\n",
    "\n",
    "Allocation Summary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Print channel-level results\n",
    "for channel in mmm_data.mmmdata_spec.paid_media_spends:\n",
    "    current = result.optimal_allocations[result.optimal_allocations[\"channel\"] == channel].iloc[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "- {channel}:\n",
    "  Optimizable bound: [{(current['constr_low']-1)*100:.0f}%, {(current['constr_up']-1)*100:.0f}%],\n",
    "  Initial spend share: {current['current_spend_share']*100:.2f}% -> Optimized bounded: {current['optimal_spend_share']*100:.2f}%\n",
    "  Initial response share: {current['current_response_share']*100:.2f}% -> Optimized bounded: {current['optimal_response_share']*100:.2f}%\n",
    "  Initial abs. mean spend: {current['current_spend']/1000:.3f}K -> Optimized: {current['optimal_spend']/1000:.3f}K [Delta = {(current['optimal_spend']/current['current_spend']-1)*100:.0f}%]\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Target Efficiency\n",
    "Optimize allocation based on target ROI/CPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenario 3: Default Target Efficiency (Target ROAS or CPA)\n",
    "print(\"\\nScenario 3: Target efficiency optimization\")\n",
    "\n",
    "# Create constraints matching R's implementation\n",
    "default_channel_constraints = AllocationConstraints(\n",
    "    channel_constr_low={\n",
    "        channel: 0.1 for channel in mmm_data.mmmdata_spec.paid_media_spends  # -90% from base for all channels\n",
    "    },\n",
    "    channel_constr_up={\n",
    "        channel: 10.0 for channel in mmm_data.mmmdata_spec.paid_media_spends  # +900% from base for all channels\n",
    "    },\n",
    "    channel_constr_multiplier=1.0,  # Don't extend bounds for target efficiency\n",
    "    is_target_efficiency=True,  # Flag this as target efficiency scenario\n",
    ")\n",
    "\n",
    "# Create configuration for target efficiency scenario\n",
    "target_efficiency_config = AllocationConfig(\n",
    "    scenario=OptimizationScenario.TARGET_EFFICIENCY,\n",
    "    constraints=default_channel_constraints,\n",
    "    date_range=\"all\",  # Use all dates like in R version\n",
    "    target_value=None,  # Will use default 80% of initial ROAS or 120% of initial CPA\n",
    "    maxeval=100000,\n",
    "    optim_algo=\"SLSQP_AUGLAG\",\n",
    "    constr_mode=ConstrMode.EQUALITY,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "result3 = allocator.allocate(target_efficiency_config)\n",
    "\n",
    "# Print results matching R format\n",
    "print(\n",
    "    f\"\"\"\n",
    "Model ID: {select_model}\n",
    "Scenario: {target_efficiency_config.scenario}\n",
    "Use case: {result3.metrics.get('use_case', '')}\n",
    "Window: {result3.metrics.get('date_range_start')}:{result3.metrics.get('date_range_end')} ({result3.metrics.get('n_periods')} {mmm_data.mmmdata_spec.interval_type})\n",
    "\n",
    "Dep. Variable Type: {mmm_data.mmmdata_spec.dep_var_type}\n",
    "Media Skipped: {result3.metrics.get('skipped_channels', 'None')}\n",
    "Relative Spend Increase: {result3.metrics.get('spend_lift_pct', 0):.0f}% ({result3.metrics.get('spend_lift_abs', 0):.0f})\n",
    "Total Response Increase (Optimized): {result3.metrics.get('response_lift', 0)*100:.0f}%\n",
    "\n",
    "Allocation Summary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Print channel-level results\n",
    "for channel in mmm_data.mmmdata_spec.paid_media_spends:\n",
    "    current = result3.optimal_allocations[result3.optimal_allocations[\"channel\"] == channel].iloc[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "- {channel}:\n",
    "  Optimizable bound: [{(current['constr_low']-1)*100:.0f}%, {(current['constr_up']-1)*100:.0f}%],\n",
    "  Initial spend share: {current['current_spend_share']*100:.2f}% -> Optimized bounded: {current['optimal_spend_share']*100:.2f}%\n",
    "  Initial response share: {current['current_response_share']*100:.2f}% -> Optimized bounded: {current['optimal_response_share']*100:.2f}%\n",
    "  Initial abs. mean spend: {current['current_spend']/1000:.3f}K -> Optimized: {current['optimal_spend']/1000:.3f}K [Delta = {(current['optimal_spend']/current['current_spend']-1)*100:.0f}%]\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for each scenario\n",
    "max_response_plotter = AllocationPlotter(result)\n",
    "target_efficiency_plotter = AllocationPlotter(result3)\n",
    "\n",
    "# Generate plots\n",
    "max_response_plots = max_response_plotter.plot_all()\n",
    "target_efficiency_plots = target_efficiency_plotter.plot_all()\n",
    "\n",
    "# Display plots\n",
    "print(\"Max Response Scenario Plots:\")\n",
    "print(\"-\" * 50)\n",
    "for plot_name, fig in max_response_plots.items():\n",
    "    display(fig)\n",
    "\n",
    "\n",
    "print(\"\\nTarget Efficiency Scenario Plots:\")\n",
    "print(\"-\" * 50)\n",
    "for plot_name, fig in target_efficiency_plots.items():\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
