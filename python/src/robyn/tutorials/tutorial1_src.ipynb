{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robyn: Marketing Mix Modeling Application\n",
    "\n",
    "This notebook demonstrates the usage of Robyn, a Marketing Mix Modeling (MMM) application. \n",
    "We'll go through the main steps of performing robyn_inputs and robyn_engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Required Libraries. Define Paths.\n",
    "\n",
    "First, be sure to setup your virtual environment. Be sure to switch over to your new environment in this notebook. \n",
    "\n",
    "-```cd {root_folder}```\n",
    "\n",
    "-```python3 -m yourvenv```\n",
    "\n",
    "-```source yourvenv/bin/activate```\n",
    "\n",
    "-```cd Robyn/python```\n",
    "\n",
    "-```pip install -r requirements.txt```\n",
    "\n",
    "\n",
    "Then import the necessary libraries. Make sure to define your paths below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add Robyn to path\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.data.entities.enums import AdstockType\n",
    "from robyn.data.entities.holidays_data import HolidaysData\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters\n",
    "from robyn.modeling.entities.modelrun_trials_config import TrialsConfig\n",
    "from robyn.modeling.model_executor import ModelExecutor\n",
    "from robyn.modeling.entities.enums import NevergradAlgorithm, Models\n",
    "from robyn.modeling.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Mock R data\n",
    "\n",
    "We need to set the base path for the data directory.\n",
    "Create a .env file in the same directory as your notebook and put in define the path to the data dir.\n",
    "for example: ROBYN_BASE_PATH=.../Robyn/R/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data...\n",
      "Holidays Data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-06</td>\n",
       "      <td>Epiphany</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-28</td>\n",
       "      <td>Carnival</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-14</td>\n",
       "      <td>Constitution Day</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-14</td>\n",
       "      <td>Good Friday</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds           holiday country  year\n",
       "0  1995-01-01    New Year's Day      AD  1995\n",
       "1  1995-01-06          Epiphany      AD  1995\n",
       "2  1995-02-28          Carnival      AD  1995\n",
       "3  1995-03-14  Constitution Day      AD  1995\n",
       "4  1995-04-14       Good Friday      AD  1995"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the simulated data and holidays data\n",
    "dt_simulated_weekly = pd.read_csv(\"resources/dt_simulated_weekly.csv\")\n",
    "\n",
    "print(\"Simulated Data...\")\n",
    "dt_simulated_weekly.head()\n",
    "\n",
    "dt_prophet_holidays = pd.read_csv(\"resources/dt_prophet_holidays.csv\")\n",
    "\n",
    "print(\"Holidays Data...\")\n",
    "dt_prophet_holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MMM Data\n",
    "\n",
    "We will now set up the MMM data specification which includes defining the dependent variable, independent variables, and the time window for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>revenue</th>\n",
       "      <th>tv_S</th>\n",
       "      <th>ooh_S</th>\n",
       "      <th>print_S</th>\n",
       "      <th>facebook_I</th>\n",
       "      <th>search_clicks_P</th>\n",
       "      <th>search_S</th>\n",
       "      <th>competitor_sales_B</th>\n",
       "      <th>facebook_S</th>\n",
       "      <th>events</th>\n",
       "      <th>newsletter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>2.754372e+06</td>\n",
       "      <td>22358.346667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12728.488889</td>\n",
       "      <td>2.430128e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8125009</td>\n",
       "      <td>7607.132915</td>\n",
       "      <td>na</td>\n",
       "      <td>19401.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2.584277e+06</td>\n",
       "      <td>28613.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.527033e+06</td>\n",
       "      <td>9837.238486</td>\n",
       "      <td>4133.333333</td>\n",
       "      <td>7901549</td>\n",
       "      <td>1141.952450</td>\n",
       "      <td>na</td>\n",
       "      <td>14791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>2.547387e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132278.4</td>\n",
       "      <td>453.866667</td>\n",
       "      <td>1.665159e+07</td>\n",
       "      <td>12044.119653</td>\n",
       "      <td>3786.666667</td>\n",
       "      <td>8300197</td>\n",
       "      <td>4256.375378</td>\n",
       "      <td>na</td>\n",
       "      <td>14544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>2.875220e+06</td>\n",
       "      <td>83450.306667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17680.000000</td>\n",
       "      <td>1.054977e+07</td>\n",
       "      <td>12268.070319</td>\n",
       "      <td>4253.333333</td>\n",
       "      <td>8122883</td>\n",
       "      <td>2800.490677</td>\n",
       "      <td>na</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2.215953e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.934090e+06</td>\n",
       "      <td>9467.248023</td>\n",
       "      <td>3613.333333</td>\n",
       "      <td>7105985</td>\n",
       "      <td>689.582605</td>\n",
       "      <td>na</td>\n",
       "      <td>15478.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE       revenue          tv_S     ooh_S       print_S  \\\n",
       "0  2015-11-23  2.754372e+06  22358.346667       0.0  12728.488889   \n",
       "1  2015-11-30  2.584277e+06  28613.453333       0.0      0.000000   \n",
       "2  2015-12-07  2.547387e+06      0.000000  132278.4    453.866667   \n",
       "3  2015-12-14  2.875220e+06  83450.306667       0.0  17680.000000   \n",
       "4  2015-12-21  2.215953e+06      0.000000  277336.0      0.000000   \n",
       "\n",
       "     facebook_I  search_clicks_P     search_S  competitor_sales_B  \\\n",
       "0  2.430128e+07         0.000000     0.000000             8125009   \n",
       "1  5.527033e+06      9837.238486  4133.333333             7901549   \n",
       "2  1.665159e+07     12044.119653  3786.666667             8300197   \n",
       "3  1.054977e+07     12268.070319  4253.333333             8122883   \n",
       "4  2.934090e+06      9467.248023  3613.333333             7105985   \n",
       "\n",
       "    facebook_S events    newsletter  \n",
       "0  7607.132915     na  19401.653846  \n",
       "1  1141.952450     na  14791.000000  \n",
       "2  4256.375378     na  14544.000000  \n",
       "3  2800.490677     na   2800.000000  \n",
       "4   689.582605     na  15478.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_mmm_data(dt_simulated_weekly) -> MMMData:\n",
    "\n",
    "    mmm_data_spec = MMMData.MMMDataSpec(\n",
    "        dep_var=\"revenue\",\n",
    "        dep_var_type=\"revenue\",\n",
    "        date_var=\"DATE\",\n",
    "        context_vars=[\"competitor_sales_B\", \"events\"],\n",
    "        paid_media_spends=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"],\n",
    "        paid_media_vars=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"],\n",
    "        organic_vars=[\"newsletter\"],\n",
    "        window_start=\"2016-01-01\",\n",
    "        window_end=\"2018-12-31\",\n",
    "    )\n",
    "\n",
    "    return MMMData(data=dt_simulated_weekly, mmmdata_spec=mmm_data_spec)\n",
    "\n",
    "\n",
    "mmm_data = setup_mmm_data(dt_simulated_weekly)\n",
    "mmm_data.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Preprocessing\n",
    "\n",
    "We will perform feature engineering to prepare the data for modeling. This includes transformations like adstock and other preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters setup complete.\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = Hyperparameters(\n",
    "    {\n",
    "        \"facebook_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"print_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"tv_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.3, 0.8],\n",
    "        ),\n",
    "        \"search_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"ooh_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"newsletter\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "    },\n",
    "    adstock=AdstockType.GEOMETRIC,\n",
    "    lambda_=0.0,\n",
    "    train_size=[0.5, 0.8],\n",
    ")\n",
    "\n",
    "print(\"Hyperparameters setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HolidaysData object\n",
    "holidays_data = HolidaysData(\n",
    "    dt_holidays=dt_prophet_holidays,\n",
    "    prophet_vars=[\"trend\", \"season\", \"holiday\"],\n",
    "    prophet_country=\"DE\",\n",
    "    prophet_signs=[\"default\", \"default\", \"default\"],\n",
    ")\n",
    "# Setup FeaturizedMMMData\n",
    "feature_engineering = FeatureEngineering(mmm_data, hyperparameters, holidays_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurized_mmm_data = feature_engineering.perform_feature_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.visualization.feature_visualization import FeaturePlotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a FeaturePlotter instance\n",
    "feature_plotter = FeaturePlotter(mmm_data, hyperparameters)\n",
    "\n",
    "# Plot spend-exposure relationship for each channel\n",
    "for channel in mmm_data.mmmdata_spec.paid_media_spends:\n",
    "    try:\n",
    "        fig = feature_plotter.plot_spend_exposure(featurized_mmm_data, channel)\n",
    "        plt.show()\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping {channel}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ModelExecutor\n",
    "model_executor = ModelExecutor(\n",
    "    mmmdata=mmm_data,\n",
    "    holidays_data=holidays_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    calibration_input=None,  # Add calibration input if available\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    ")\n",
    "\n",
    "# Setup TrialsConfig\n",
    "trials_config = TrialsConfig(iterations=10, trials=5)  # Set to the number of cores you want to use\n",
    "\n",
    "print(\n",
    "    f\">>> Starting {trials_config.trials} trials with {trials_config.iterations} iterations each using {NevergradAlgorithm.TWO_POINTS_DE.value} nevergrad algorithm on x cores...\"\n",
    ")\n",
    "\n",
    "# Run the model\n",
    "\n",
    "output_models = model_executor.model_run(\n",
    "    trials_config=trials_config,\n",
    "    ts_validation=False,  # changed from True to False -> deacitvate\n",
    "    add_penalty_factor=False,\n",
    "    rssd_zero_penalty=True,\n",
    "    cores=8,\n",
    "    nevergrad_algo=NevergradAlgorithm.TWO_POINTS_DE,\n",
    "    intercept=True,\n",
    "    intercept_sign=\"non_negative\",\n",
    "    model_name=Models.RIDGE,\n",
    ")\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# TODO need to fix graph outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1. Display the MOO Distribution Plot\n",
    "if \"moo_distrb_plot\" in output_models.convergence:\n",
    "    moo_distrb_plot = output_models.convergence[\"moo_distrb_plot\"]\n",
    "    display(Image(data=base64.b64decode(moo_distrb_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Display the MOO Cloud Plot\n",
    "if \"moo_cloud_plot\" in output_models.convergence:\n",
    "    moo_cloud_plot = output_models.convergence[\"moo_cloud_plot\"]\n",
    "    display(Image(data=base64.b64decode(moo_cloud_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Print convergence messages\n",
    "if \"conv_msg\" in output_models.convergence:\n",
    "    for msg in output_models.convergence[\"conv_msg\"]:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Display time series validation and convergence plots\n",
    "if \"ts_validation_plot\" in output_models.convergence:\n",
    "    ts_validation_plot = output_models.convergence[\"ts_validation_plot\"]\n",
    "    display(Image(data=base64.b64decode(ts_validation_plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_id = output_models.select_id\n",
    "print(f\"Best model ID: {best_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.modeling.entities.modeloutputs import ModelOutputs, Trial\n",
    "from robyn.modeling.pareto.pareto_optimizer import ParetoOptimizer\n",
    "from robyn.data.entities.enums import DependentVarType, PaidMediaSigns, OrganicSigns, ContextSigns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create ParetoOptimizer instance\n",
    "pareto_optimizer = ParetoOptimizer(mmm_data, output_models, hyperparameters, featurized_mmm_data, holidays_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run optimize function\n",
    "pareto_result = pareto_optimizer.optimize(pareto_fronts=\"auto\", min_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check results\n",
    "print(\"Pareto Optimization Results:\")\n",
    "print(f\"Number of Pareto fronts: {pareto_result.pareto_solutions}\")\n",
    "print(f\"MediaVecCollect: {pareto_result.media_vec_collect.shape, pareto_result.media_vec_collect}\")\n",
    "print(\"\\Hyper parameter solutions:\")\n",
    "print(pareto_result.result_hyp_param)\n",
    "\n",
    "print(\"\\nAggregated decomposition results:\")\n",
    "print(pareto_result.x_decomp_agg)\n",
    "print(\"\\result Calibration:\")\n",
    "print(pareto_result.result_calibration)\n",
    "print(\"\\nx Decomp Vec Collect:\")\n",
    "print(pareto_result.x_decomp_vec_collect.shape, pareto_result.x_decomp_vec_collect)\n",
    "print(\"\\nCarryover percentage all:\")\n",
    "print(pareto_result.df_caov_pct_all.shape, pareto_result.df_caov_pct_all)\n",
    "print(\"\\Plot Data Collected\")\n",
    "print(\"NUMBER OF PLOTS Data collected for:\", len(pareto_result.plot_data_collect))\n",
    "print(\"Plot data for solid 5_221_9\", pareto_result.plot_data_collect)\n",
    "\n",
    "# 6. Validate logic\n",
    "assert pareto_result.pareto_fronts == \"auto\" or isinstance(\n",
    "    pareto_result.pareto_fronts, int\n",
    "), \"Invalid pareto_fronts value\"\n",
    "assert not pareto_result.result_hyp_param.empty, \"Empty result_hyp_param DataFrame\"\n",
    "assert not pareto_result.x_decomp_agg.empty, \"Empty x_decomp_agg DataFrame\"\n",
    "\n",
    "print(\"\\nAll assertions passed. The optimize function is working as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pareto_result.pareto_solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Setup and Import\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, Union, List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import necessary Robyn classes\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.modeling.entities.modeloutputs import ModelOutputs\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters\n",
    "from robyn.allocator.entities.enums import OptimizationScenario, ConstrMode\n",
    "from robyn.allocator.budget_allocator import BudgetAllocator\n",
    "from robyn.modeling.pareto.pareto_optimizer import ParetoResult\n",
    "from robyn.allocator.entities.allocation_config import AllocationConfig\n",
    "from robyn.allocator.entities.allocation_constraints import AllocationConstraints\n",
    "from robyn.visualization.allocator_plotter import AllocationPlotter\n",
    "from utils.data_mapper import load_data_from_json, import_input_collect, import_output_collect, import_output_models\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pareto_result.result_hyp_param[\"sol_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use the correct model ID from your pareto results\n",
    "available_models = pareto_result.result_hyp_param[\"sol_id\"].unique()  # or 'solID' if that's the column name\n",
    "print(f\"Available models: {available_models}\")\n",
    "# Initialize allocator with a valid model ID\n",
    "select_model = available_models[0]  # Use first available model\n",
    "\n",
    "# Initialize budget allocator\n",
    "allocator = BudgetAllocator(\n",
    "    mmm_data=mmm_data,\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    "    model_outputs=output_models,\n",
    "    pareto_result=pareto_result,  # Get ParetoResult from import_output_collect()\n",
    "    select_model=select_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Different Optimization Scenarios\n",
    "\n",
    "### Scenario 1: Default Max Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base constraints matching R example\n",
    "channel_constraints = AllocationConstraints(\n",
    "    channel_constr_low={\n",
    "        \"tv_S\": 0.7,  # -30% from base\n",
    "        \"ooh_S\": 0.7,\n",
    "        \"print_S\": 0.7,\n",
    "        \"facebook_S\": 0.7,\n",
    "        \"search_S\": 0.7,\n",
    "    },\n",
    "    channel_constr_up={\n",
    "        \"tv_S\": 1.2,  # +20% from base\n",
    "        \"ooh_S\": 1.5,  # +50% from base\n",
    "        \"print_S\": 1.5,\n",
    "        \"facebook_S\": 1.5,\n",
    "        \"search_S\": 1.5,\n",
    "    },\n",
    "    channel_constr_multiplier=3.0,\n",
    ")\n",
    "\n",
    "# Configure max response scenario\n",
    "max_response_config = AllocationConfig(\n",
    "    scenario=OptimizationScenario.MAX_RESPONSE,\n",
    "    constraints=channel_constraints,\n",
    "    date_range=\"last\",  # Use last period as initial\n",
    "    total_budget=None,  # Use historical budget\n",
    "    maxeval=100000,\n",
    "    optim_algo=\"SLSQP_AUGLAG\",\n",
    "    constr_mode=ConstrMode.EQUALITY,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "result = allocator.allocate(max_response_config)\n",
    "\n",
    "# Print results\n",
    "print(\n",
    "    f\"\"\"\n",
    "Model ID: {select_model}\n",
    "Scenario: {max_response_config.scenario}\n",
    "Use case: {result.metrics.get('use_case', '')}\n",
    "Window: {result.metrics.get('date_range_start')}:{result.metrics.get('date_range_end')} ({result.metrics.get('n_periods')} {mmm_data.mmmdata_spec.interval_type})\n",
    "\n",
    "Dep. Variable Type: {mmm_data.mmmdata_spec.dep_var_type}\n",
    "Media Skipped: {result.metrics.get('skipped_channels', 'None')}\n",
    "Relative Spend Increase: {result.metrics.get('spend_lift_pct', 0):.1f}% ({result.metrics.get('spend_lift_abs', 0):+.0f}K)\n",
    "Total Response Increase (Optimized): {result.metrics.get('response_lift', 0)*100:.1f}%\n",
    "\n",
    "Allocation Summary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Print channel-level results\n",
    "for channel in mmm_data.mmmdata_spec.paid_media_spends:\n",
    "    current = result.optimal_allocations[result.optimal_allocations[\"channel\"] == channel].iloc[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "- {channel}:\n",
    "  Optimizable bound: [{(current['constr_low']-1)*100:.0f}%, {(current['constr_up']-1)*100:.0f}%],\n",
    "  Initial spend share: {current['current_spend_share']*100:.2f}% -> Optimized bounded: {current['optimal_spend_share']*100:.2f}%\n",
    "  Initial response share: {current['current_response_share']*100:.2f}% -> Optimized bounded: {current['optimal_response_share']*100:.2f}%\n",
    "  Initial abs. mean spend: {current['current_spend']/1000:.3f}K -> Optimized: {current['optimal_spend']/1000:.3f}K [Delta = {(current['optimal_spend']/current['current_spend']-1)*100:.0f}%]\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Target Efficiency\n",
    "Optimize allocation based on target ROI/CPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scenario 3: Default Target Efficiency (Target ROAS or CPA)\n",
    "print(\"\\nScenario 3: Target efficiency optimization\")\n",
    "\n",
    "# Create constraints matching R's implementation\n",
    "default_channel_constraints = AllocationConstraints(\n",
    "    channel_constr_low={\n",
    "        channel: 0.1 for channel in mmm_data.mmmdata_spec.paid_media_spends  # -90% from base for all channels\n",
    "    },\n",
    "    channel_constr_up={\n",
    "        channel: 10.0 for channel in mmm_data.mmmdata_spec.paid_media_spends  # +900% from base for all channels\n",
    "    },\n",
    "    channel_constr_multiplier=1.0,  # Don't extend bounds for target efficiency\n",
    "    is_target_efficiency=True,  # Flag this as target efficiency scenario\n",
    ")\n",
    "\n",
    "# Create configuration for target efficiency scenario\n",
    "target_efficiency_config = AllocationConfig(\n",
    "    scenario=OptimizationScenario.TARGET_EFFICIENCY,\n",
    "    constraints=default_channel_constraints,\n",
    "    date_range=\"all\",  # Use all dates like in R version\n",
    "    target_value=None,  # Will use default 80% of initial ROAS or 120% of initial CPA\n",
    "    maxeval=100000,\n",
    "    optim_algo=\"SLSQP_AUGLAG\",\n",
    "    constr_mode=ConstrMode.EQUALITY,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "result3 = allocator.allocate(target_efficiency_config)\n",
    "\n",
    "# Print results matching R format\n",
    "print(\n",
    "    f\"\"\"\n",
    "Model ID: {select_model}\n",
    "Scenario: {target_efficiency_config.scenario}\n",
    "Use case: {result3.metrics.get('use_case', '')}\n",
    "Window: {result3.metrics.get('date_range_start')}:{result3.metrics.get('date_range_end')} ({result3.metrics.get('n_periods')} {mmm_data.mmmdata_spec.interval_type})\n",
    "\n",
    "Dep. Variable Type: {mmm_data.mmmdata_spec.dep_var_type}\n",
    "Media Skipped: {result3.metrics.get('skipped_channels', 'None')}\n",
    "Relative Spend Increase: {result3.metrics.get('spend_lift_pct', 0):.0f}% ({result3.metrics.get('spend_lift_abs', 0):.0f})\n",
    "Total Response Increase (Optimized): {result3.metrics.get('response_lift', 0)*100:.0f}%\n",
    "\n",
    "Allocation Summary:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Print channel-level results\n",
    "for channel in mmm_data.mmmdata_spec.paid_media_spends:\n",
    "    current = result3.optimal_allocations[result3.optimal_allocations[\"channel\"] == channel].iloc[0]\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "- {channel}:\n",
    "  Optimizable bound: [{(current['constr_low']-1)*100:.0f}%, {(current['constr_up']-1)*100:.0f}%],\n",
    "  Initial spend share: {current['current_spend_share']*100:.2f}% -> Optimized bounded: {current['optimal_spend_share']*100:.2f}%\n",
    "  Initial response share: {current['current_response_share']*100:.2f}% -> Optimized bounded: {current['optimal_response_share']*100:.2f}%\n",
    "  Initial abs. mean spend: {current['current_spend']/1000:.3f}K -> Optimized: {current['optimal_spend']/1000:.3f}K [Delta = {(current['optimal_spend']/current['current_spend']-1)*100:.0f}%]\n",
    "\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for each scenario\n",
    "max_response_plotter = AllocationPlotter(result)\n",
    "target_efficiency_plotter = AllocationPlotter(result3)\n",
    "\n",
    "# Generate plots\n",
    "max_response_plots = max_response_plotter.plot_all()\n",
    "target_efficiency_plots = target_efficiency_plotter.plot_all()\n",
    "\n",
    "# Display plots\n",
    "print(\"Max Response Scenario Plots:\")\n",
    "print(\"-\" * 50)\n",
    "for plot_name, fig in max_response_plots.items():\n",
    "    display(fig)\n",
    "\n",
    "\n",
    "print(\"\\nTarget Efficiency Scenario Plots:\")\n",
    "print(\"-\" * 50)\n",
    "for plot_name, fig in target_efficiency_plots.items():\n",
    "    display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
