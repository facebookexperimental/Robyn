{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robyn: Advanced Marketing Mix Modeling (Source Implementation)\n",
    "\n",
    "This notebook demonstrates how to use Robyn's core components directly for advanced Marketing Mix Modeling (MMM). This approach provides more granular control over the modeling process.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install Robyn using pip:\n",
    "\n",
    "- pip install robynpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "We'll import the core components directly from Robyn's source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 18:55:15,713 - robyn - INFO - Logging is set up to console only.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")\n",
    "\n",
    "import pandas as pd\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.data.entities.enums import AdstockType\n",
    "from robyn.data.entities.holidays_data import HolidaysData\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters\n",
    "from robyn.modeling.entities.modelrun_trials_config import TrialsConfig\n",
    "from robyn.modeling.model_executor import ModelExecutor\n",
    "from robyn.modeling.entities.enums import NevergradAlgorithm, Models\n",
    "from robyn.modeling.feature_engineering import FeatureEngineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "For this demonstration, we'll use simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the simulated data and holidays data\n",
    "dt_simulated_weekly = pd.read_csv(\"resources/dt_simulated_weekly.csv\")\n",
    "\n",
    "dt_prophet_holidays = pd.read_csv(\"resources/dt_prophet_holidays.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure MMM Data\n",
    "\n",
    "Define the model specification including dependent variables, independent variables, and analysis window. Here's what each parameter means:\n",
    "\n",
    "### Key Components:\n",
    "- `dep_var`: Your target metric (e.g., \"revenue\", \"conversions\")\n",
    "- `dep_var_type`: Type of dependent variable (\"revenue\" for ROI or \"conversion\" for CPA)\n",
    "- `date_var`: Column name containing dates\n",
    "- `window_start/end`: Analysis time period\n",
    "\n",
    "### Variable Types:\n",
    "- `paid_media_spends`: Columns containing media spend data (e.g., TV, Facebook, Search)\n",
    "- `paid_media_vars`: Media exposure metrics (impressions, clicks) in same order as spends\n",
    "- `context_vars`: External factors (e.g., competitor activities, events, seasonality)\n",
    "- `organic_vars`: Marketing activities without direct spend (e.g., email, social posts)\n",
    "\n",
    "Example configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mmm_data(dt_simulated_weekly) -> MMMData:\n",
    "\n",
    "    mmm_data_spec = MMMData.MMMDataSpec(\n",
    "        dep_var=\"revenue\",\n",
    "        dep_var_type=\"revenue\",\n",
    "        date_var=\"DATE\",\n",
    "        context_vars=[\"competitor_sales_B\", \"events\"],\n",
    "        paid_media_spends=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"],\n",
    "        paid_media_vars=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"],\n",
    "        organic_vars=[\"newsletter\"],\n",
    "        window_start=\"2016-01-01\",\n",
    "        window_end=\"2018-12-31\",\n",
    "    )\n",
    "\n",
    "    return MMMData(data=dt_simulated_weekly, mmmdata_spec=mmm_data_spec)\n",
    "\n",
    "\n",
    "mmm_data = setup_mmm_data(dt_simulated_weekly)\n",
    "mmm_data.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Setup\n",
    "\n",
    "Configure hyperparameters and holiday data for feature preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Hyperparameters\n",
    "\n",
    "Hyperparameters control how media effects are modeled. Each channel requires three key parameters:\n",
    "\n",
    "### Media Channel Parameters:\n",
    "- `alphas`: Controls saturation curve shape [0.5, 3]\n",
    "  - Lower values (0.5-1): More diminishing returns\n",
    "  - Higher values (2-3): More S-shaped response\n",
    "  \n",
    "- `gammas`: Controls saturation curve inflection point [0.3, 1]\n",
    "  - Lower values: Earlier diminishing returns\n",
    "  - Higher values: Later diminishing returns\n",
    "\n",
    "- `thetas`: Controls adstock decay rate [0, 0.8]\n",
    "  - Lower values (0-0.2): Fast decay (e.g., Search, Social)\n",
    "  - Medium values (0.1-0.4): Medium decay (e.g., Print, OOH)\n",
    "  - Higher values (0.3-0.8): Slow decay (e.g., TV)\n",
    "\n",
    "### Global Parameters:\n",
    "- `adstock`: Type of carryover effect modeling\n",
    "  - \"geometric\": Fixed decay rate\n",
    "  - \"weibull_cdf\": Flexible decay with cumulative distribution\n",
    "  - \"weibull_pdf\": Flexible decay with potential peak delay\n",
    "\n",
    "- `lambda_`: Ridge regression regularization [0, 1]\n",
    "- `train_size`: Proportion of data for training [0.5, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = Hyperparameters(\n",
    "    {\n",
    "        \"facebook_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"print_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"tv_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.3, 0.8],\n",
    "        ),\n",
    "        \"search_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"ooh_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"newsletter\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "    },\n",
    "    adstock=AdstockType.GEOMETRIC,\n",
    "    lambda_=[0, 1],\n",
    "    train_size=[0.5, 0.8],\n",
    ")\n",
    "\n",
    "print(\"Hyperparameters setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Holiday Data\n",
    "\n",
    "Holiday data helps capture seasonality and special events in your model. The HolidaysData configuration includes:\n",
    "\n",
    "### Components:\n",
    "- `dt_holidays`: DataFrame containing holiday/events data\n",
    "- `prophet_vars`: Time components to model:\n",
    "  - \"trend\": Long-term trend\n",
    "  - \"season\": Seasonal patterns\n",
    "  - \"holiday\": Holiday/event effects\n",
    "- `prophet_country`: Country code for built-in holidays (e.g., \"DE\" for Germany)\n",
    "- `prophet_signs`: Effect direction for each prophet_var:\n",
    "  - \"default\": Let the model determine direction\n",
    "  - \"positive\": Force positive effect\n",
    "  - \"negative\": Force negative effect\n",
    "\n",
    "Note: You can add custom events (school breaks, promotional periods, etc.) to the holidays data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HolidaysData object\n",
    "holidays_data = HolidaysData(\n",
    "    dt_holidays=dt_prophet_holidays,\n",
    "    prophet_vars=[\"trend\", \"season\", \"holiday\"],\n",
    "    prophet_country=\"DE\",\n",
    "    prophet_signs=[\"default\", \"default\", \"default\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Feature Engineering\n",
    "\n",
    "Process and transform features using the FeatureEngineering component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup FeaturizedMMMData\n",
    "feature_engineering = FeatureEngineering(mmm_data, hyperparameters, holidays_data)\n",
    "\n",
    "featurized_mmm_data = feature_engineering.perform_feature_engineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Feature Relationships\n",
    "\n",
    "Plot spend-exposure relationships for channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.visualization.feature_visualization import FeaturePlotter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "feature_plotter = FeaturePlotter(mmm_data, hyperparameters, featurized_mmm_data)\n",
    "results_list = featurized_mmm_data.modNLS[\"results\"]\n",
    "\n",
    "for result in results_list:\n",
    "    channel = result[\"channel\"]\n",
    "    try:\n",
    "        fig = feature_plotter.plot_spend_exposure(channel)\n",
    "        plt.show()\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping {channel}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "### Training Configuration:\n",
    "- `trials`: Number of parallel optimization trials (e.g., 5)\n",
    "- `iterations`: Optimization iterations per trial (e.g., 2000)\n",
    "- `ts_validation`: Whether to use time-series validation\n",
    "- `cores`: Number of CPU cores to use for parallel processing\n",
    "- `nevergrad_algo`: Optimization algorithm (TWO_POINTS_DE recommended)\n",
    "- `model_name`: Model type (RIDGE regression recommended)\n",
    "\n",
    "Parameters:\n",
    "- `add_penalty_factor`: Additional regularization for stability\n",
    "- `rssd_zero_penalty`: Penalize unrealistic zero contributions\n",
    "- `intercept`: Include intercept term\n",
    "- `intercept_sign`: Control intercept direction\n",
    "\n",
    "Note: More iterations and trials generally lead to better results but increase computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_executor = ModelExecutor(\n",
    "    mmmdata=mmm_data,\n",
    "    holidays_data=holidays_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    calibration_input=None,\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    ")\n",
    "\n",
    "trials_config = TrialsConfig(iterations=54, trials=5)\n",
    "\n",
    "output_models = model_executor.model_run(\n",
    "    trials_config=trials_config,\n",
    "    ts_validation=True,\n",
    "    add_penalty_factor=False,\n",
    "    rssd_zero_penalty=True,\n",
    "    cores=8,\n",
    "    nevergrad_algo=NevergradAlgorithm.TWO_POINTS_DE,\n",
    "    intercept=True,\n",
    "    intercept_sign=\"non_negative\",\n",
    "    model_name=Models.RIDGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Clustering\n",
    "\n",
    "### 1. Pareto Optimization\n",
    "Pareto optimization helps select the best models by balancing multiple objectives:\n",
    "- Model accuracy (NRMSE)\n",
    "- Decomposition accuracy\n",
    "- Model robustness\n",
    "\n",
    "Parameters:\n",
    "- `pareto_fronts`: Number of Pareto fronts to consider (\"auto\" recommended)\n",
    "- `min_candidates`: Minimum number of models to retain (e.g., 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.modeling.pareto.pareto_optimizer import ParetoOptimizer\n",
    "\n",
    "# 3. Create ParetoOptimizer instance\n",
    "pareto_optimizer = ParetoOptimizer(\n",
    "    mmm_data, output_models, hyperparameters, featurized_mmm_data, holidays_data\n",
    ")\n",
    "\n",
    "# 4. Run optimize function\n",
    "pareto_result = pareto_optimizer.optimize(pareto_fronts=\"auto\", min_candidates=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Clustering\n",
    "Clustering groups similar models together to identify stable solutions.\n",
    "\n",
    "Configuration parameters:\n",
    "- `dep_var_type`: Type of dependent variable (revenue/conversion)\n",
    "- `cluster_by`: Clustering criterion (HYPERPARAMETERS recommended)\n",
    "- `max_clusters`: Maximum number of clusters to consider\n",
    "- `min_clusters`: Minimum number of clusters\n",
    "- `weights`: Importance weights for clustering criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.modeling.clustering.clustering_config import ClusteringConfig, ClusterBy\n",
    "from robyn.modeling.clustering.cluster_builder import ClusterBuilder\n",
    "from robyn.data.entities.enums import DependentVarType\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"iframe\"\n",
    "\n",
    "cluster_configs = ClusteringConfig(\n",
    "    dep_var_type=DependentVarType(mmm_data.mmmdata_spec.dep_var_type),\n",
    "    cluster_by=ClusterBy.HYPERPARAMETERS,\n",
    "    max_clusters=10,\n",
    "    min_clusters=3,\n",
    "    weights=[1.0, 1.0, 1.0],\n",
    ")\n",
    "\n",
    "cluster_builder = ClusterBuilder(pareto_result=pareto_result)\n",
    "\n",
    "\n",
    "cluster_results = cluster_builder.cluster_models(cluster_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reestablish Pareto Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.modeling.pareto.pareto_utils import ParetoUtils\n",
    "\n",
    "utils = ParetoUtils()\n",
    "pareto_result = utils.process_pareto_clustered_results(\n",
    "    pareto_result,\n",
    "    clustered_result=cluster_results,\n",
    "    ran_cluster=True,\n",
    "    ran_calibration=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budget Allocation Optimization\n",
    "\n",
    "Robyn provides different scenarios for budget allocation optimization. Let's explore the \"max_response\" scenario:\n",
    "\n",
    "### Scenario: Maximum Response\n",
    "This scenario answers the question: \"What's the maximum return given certain spend constraints?\"\n",
    "\n",
    "Key parameters:\n",
    "- `total_budget`: When set to None, uses the total spend in the selected date range\n",
    "- `channel_constr_low`: Minimum spend multiplier (e.g., 0.7 means channel spend can't go below 70% of current)\n",
    "- `channel_constr_up`: Maximum spend multiplier per channel (e.g., 1.5 means channel spend can't exceed 150% of current)\n",
    "- `channel_constr_multiplier`: Extends bounds for wider optimization insights\n",
    "- `date_range`: Period for optimization (\"all\", \"last_X\", or specific date range)\n",
    "\n",
    "Note: Other scenarios include:\n",
    "- \"target_efficiency\": Optimize spend to hit specific ROAS or CPA targets\n",
    "- \"min_spend\": Find minimum spend required to hit response targets\n",
    "- \"max_response_expected\": Maximize expected response within confidence intervals\n",
    "\n",
    "For this example, we'll demonstrate the \"max_response\" scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.allocator.entities.allocation_params import AllocatorParams\n",
    "from robyn.allocator.entities.allocation_result import (\n",
    "    AllocationResult,\n",
    "    OptimOutData,\n",
    "    MainPoints,\n",
    ")\n",
    "from robyn.allocator.entities.optimization_result import OptimizationResult\n",
    "from robyn.allocator.entities.constraints import Constraints\n",
    "from robyn.allocator.optimizer import BudgetAllocator\n",
    "from robyn.allocator.constants import (\n",
    "    SCENARIO_MAX_RESPONSE,\n",
    "    ALGO_SLSQP_AUGLAG,\n",
    "    CONSTRAINT_MODE_EQ,\n",
    "    DEFAULT_CONSTRAINT_MULTIPLIER,\n",
    "    DATE_RANGE_ALL,\n",
    ")\n",
    "\n",
    "select_model = pareto_result.pareto_solutions[1]\n",
    "\n",
    "# Create allocator parameters matching R Example 1\n",
    "allocator_params = AllocatorParams(\n",
    "    scenario=SCENARIO_MAX_RESPONSE,\n",
    "    total_budget=None,  # When None, uses total spend in date_range\n",
    "    target_value=None,\n",
    "    date_range=\"all\",\n",
    "    channel_constr_low=[0.7],  # Single value for all channels\n",
    "    channel_constr_up=[1.2, 1.5, 1.5, 1.5, 1.5],  # Different values per channel\n",
    "    channel_constr_multiplier=3.0,\n",
    "    optim_algo=\"SLSQP_AUGLAG\",\n",
    "    maxeval=100000,\n",
    "    constr_mode=CONSTRAINT_MODE_EQ,\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "# Initialize budget allocator\n",
    "max_response_allocator = BudgetAllocator(\n",
    "    mmm_data=mmm_data,\n",
    "    featurized_mmm_data=featurized_mmm_data,\n",
    "    hyperparameters=hyperparameters,\n",
    "    pareto_result=pareto_result,\n",
    "    select_model=select_model,\n",
    "    params=allocator_params,\n",
    ")\n",
    "\n",
    "## Step 3: Run Optimization\n",
    "max_response_result = max_response_allocator.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Create summary of optimization results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Channel\": max_response_result.dt_optimOut.channels,\n",
    "        \"Initial Spend\": max_response_result.dt_optimOut.init_spend_unit,\n",
    "        \"Optimized Spend\": max_response_result.dt_optimOut.optm_spend_unit,\n",
    "        \"Spend Change %\": (\n",
    "            max_response_result.dt_optimOut.optm_spend_unit\n",
    "            / max_response_result.dt_optimOut.init_spend_unit\n",
    "            - 1\n",
    "        )\n",
    "        * 100,\n",
    "        \"Initial Response\": max_response_result.dt_optimOut.init_response_unit,\n",
    "        \"Optimized Response\": max_response_result.dt_optimOut.optm_response_unit,\n",
    "        \"Response Lift %\": (\n",
    "            max_response_result.dt_optimOut.optm_response_unit\n",
    "            / max_response_result.dt_optimOut.init_response_unit\n",
    "            - 1\n",
    "        )\n",
    "        * 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(results_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Generate allocation visualization plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robyn.visualization.allocator_visualizer import AllocatorPlotter\n",
    "\n",
    "plotter = AllocatorPlotter(\n",
    "    allocation_result=max_response_result, budget_allocator=max_response_allocator\n",
    ")\n",
    "\n",
    "plots = plotter.plot_all(display_plots=True, export_location=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
