{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Pareto Optimizer\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.modeling.entities.modeloutputs import ModelOutputs, Trial\n",
    "from robyn.modeling.pareto.pareto_optimizer import ParetoOptimizer\n",
    "from robyn.data.entities.enums import (\n",
    "    DependentVarType,\n",
    "    PaidMediaSigns,\n",
    "    OrganicSigns,\n",
    "    ContextSigns,\n",
    ")\n",
    "\n",
    "from robyn.tutorials.utils.data_mapper import (\n",
    "    import_output_models,\n",
    "    import_input_collect,\n",
    "    load_data_from_json,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from JSON\n",
    "inputCollect = load_data_from_json(\n",
    "    \"/Users/yijuilee/project_robyn/original/Robyn_original_2/Robyn/robyn_api/data/test_Pareto_2000_iterations_5_trials_InputCollect.json\"\n",
    ")\n",
    "outputModel = load_data_from_json(\n",
    "    \"/Users/yijuilee/project_robyn/original/Robyn_original_2/Robyn/robyn_api/data/test_Pareto_2000_iterations_5_trials_OutputModels.json\"\n",
    ")\n",
    "input_collect = import_input_collect(inputCollect)\n",
    "model_outputs = import_output_models(outputModel)\n",
    "display((model_outputs.hyper_bound_ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmm_data = input_collect[\"mmm_data\"]\n",
    "# display(mmm_data.data.head())\n",
    "# Display Model Outputs\n",
    "\n",
    "model_outputs = model_outputs\n",
    "# display((model_outputs.trials[0].result_hyp_param))\n",
    "\n",
    "hyperparameters = input_collect[\"hyperparameters\"]\n",
    "# display(hyperparameters)\n",
    "\n",
    "featurized_mmm_data = input_collect[\"featurized_mmm_data\"]\n",
    "\n",
    "holidays_data = input_collect[\"holidays_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create ParetoOptimizer instance\n",
    "pareto_optimizer = ParetoOptimizer(\n",
    "    mmm_data, model_outputs, hyperparameters, featurized_mmm_data, holidays_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Run optimize function\n",
    "pareto_result = pareto_optimizer.optimize(pareto_fronts=\"auto\", min_candidates=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check results\n",
    "print(\"Pareto Optimization Results:\")\n",
    "print(f\"Number of Pareto fronts: {pareto_result.pareto_solutions}\")\n",
    "print(\n",
    "    f\"MediaVecCollect: {pareto_result.media_vec_collect.shape, pareto_result.media_vec_collect}\"\n",
    ")\n",
    "print(\"\\Hyper parameter solutions:\")\n",
    "print(pareto_result.result_hyp_param)\n",
    "\n",
    "print(\"\\nAggregated decomposition results:\")\n",
    "print(pareto_result.x_decomp_agg)\n",
    "print(\"\\result Calibration:\")\n",
    "print(pareto_result.result_calibration)\n",
    "print(\"\\nx Decomp Vec Collect:\")\n",
    "print(pareto_result.x_decomp_vec_collect.shape, pareto_result.x_decomp_vec_collect)\n",
    "print(\"\\nCarryover percentage all:\")\n",
    "print(pareto_result.df_caov_pct_all.shape, pareto_result.df_caov_pct_all)\n",
    "print(\"\\Plot Data Collected\")\n",
    "# print(\"NUMBER OF PLOTS Data collected for:\", len(pareto_result.plot_data_collect[\"3_206_6\"]))\n",
    "# print(\"Plot data for solid 3_206_6\", pareto_result.plot_data_collect[\"3_206_6\"])\n",
    "\n",
    "# 6. Validate logic\n",
    "assert pareto_result.pareto_fronts == \"auto\" or isinstance(\n",
    "    pareto_result.pareto_fronts, int\n",
    "), \"Invalid pareto_fronts value\"\n",
    "assert not pareto_result.result_hyp_param.empty, \"Empty result_hyp_param DataFrame\"\n",
    "assert not pareto_result.x_decomp_agg.empty, \"Empty x_decomp_agg DataFrame\"\n",
    "\n",
    "print(\"\\nAll assertions passed. The optimize function is working as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pareto_result.x_decomp_agg[pareto_result.x_decomp_agg[\"sol_id\"] == \"5_221_9\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only export this to a pickle file if you plan to use the results and the mmm_data in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pareto_result.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pareto_result, f)\n",
    "with open(\"mmmdata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mmm_data, f)\n",
    "with open(\"holidays_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(holidays_data, f)\n",
    "with open(\"featurized_mmm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(featurized_mmm_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
