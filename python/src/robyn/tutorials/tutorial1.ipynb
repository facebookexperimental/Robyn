{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f2f84a",
   "metadata": {},
   "source": [
    "# Robyn: Marketing Mix Modeling Application\n",
    "\n",
    "This notebook demonstrates the usage of Robyn, a Marketing Mix Modeling (MMM) application. We'll go through the main steps of initializing the model, running it, and performing budget allocation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd474b7",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Import Required Libraries and Create Synthetic Data\n",
    "\n",
    "First, let's import the necessary libraries and create some synthetic data for our demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8146e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:24:50,881 - robyn - INFO - Logging is set up to console only.\n",
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/yijuilee/robynpy_release_reviews/Robyn/python/src\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from robyn.robyn import Robyn\n",
    "from robyn.data.entities.mmmdata import MMMData\n",
    "from robyn.data.entities.holidays_data import HolidaysData\n",
    "from robyn.data.entities.hyperparameters import Hyperparameters, ChannelHyperparameters\n",
    "from robyn.data.entities.calibration_input import CalibrationInput, ChannelCalibrationData\n",
    "from robyn.data.entities.enums import AdstockType, DependentVarType, CalibrationScope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442024b2",
   "metadata": {},
   "source": [
    "## 2.1 Load simulated data.\n",
    "\n",
    "You need to replace this with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f14728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>revenue</th>\n",
       "      <th>tv_S</th>\n",
       "      <th>ooh_S</th>\n",
       "      <th>print_S</th>\n",
       "      <th>facebook_I</th>\n",
       "      <th>search_clicks_P</th>\n",
       "      <th>search_S</th>\n",
       "      <th>competitor_sales_B</th>\n",
       "      <th>facebook_S</th>\n",
       "      <th>events</th>\n",
       "      <th>newsletter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>2.754372e+06</td>\n",
       "      <td>22358.346667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12728.488889</td>\n",
       "      <td>2.430128e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8125009</td>\n",
       "      <td>7607.132915</td>\n",
       "      <td>na</td>\n",
       "      <td>19401.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-30</td>\n",
       "      <td>2.584277e+06</td>\n",
       "      <td>28613.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.527033e+06</td>\n",
       "      <td>9837.238486</td>\n",
       "      <td>4133.333333</td>\n",
       "      <td>7901549</td>\n",
       "      <td>1141.952450</td>\n",
       "      <td>na</td>\n",
       "      <td>14791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-07</td>\n",
       "      <td>2.547387e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132278.4</td>\n",
       "      <td>453.866667</td>\n",
       "      <td>1.665159e+07</td>\n",
       "      <td>12044.119653</td>\n",
       "      <td>3786.666667</td>\n",
       "      <td>8300197</td>\n",
       "      <td>4256.375378</td>\n",
       "      <td>na</td>\n",
       "      <td>14544.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>2.875220e+06</td>\n",
       "      <td>83450.306667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17680.000000</td>\n",
       "      <td>1.054977e+07</td>\n",
       "      <td>12268.070319</td>\n",
       "      <td>4253.333333</td>\n",
       "      <td>8122883</td>\n",
       "      <td>2800.490677</td>\n",
       "      <td>na</td>\n",
       "      <td>2800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2.215953e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277336.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.934090e+06</td>\n",
       "      <td>9467.248023</td>\n",
       "      <td>3613.333333</td>\n",
       "      <td>7105985</td>\n",
       "      <td>689.582605</td>\n",
       "      <td>na</td>\n",
       "      <td>15478.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE       revenue          tv_S     ooh_S       print_S  \\\n",
       "0  2015-11-23  2.754372e+06  22358.346667       0.0  12728.488889   \n",
       "1  2015-11-30  2.584277e+06  28613.453333       0.0      0.000000   \n",
       "2  2015-12-07  2.547387e+06      0.000000  132278.4    453.866667   \n",
       "3  2015-12-14  2.875220e+06  83450.306667       0.0  17680.000000   \n",
       "4  2015-12-21  2.215953e+06      0.000000  277336.0      0.000000   \n",
       "\n",
       "     facebook_I  search_clicks_P     search_S  competitor_sales_B  \\\n",
       "0  2.430128e+07         0.000000     0.000000             8125009   \n",
       "1  5.527033e+06      9837.238486  4133.333333             7901549   \n",
       "2  1.665159e+07     12044.119653  3786.666667             8300197   \n",
       "3  1.054977e+07     12268.070319  4253.333333             8122883   \n",
       "4  2.934090e+06      9467.248023  3613.333333             7105985   \n",
       "\n",
       "    facebook_S events    newsletter  \n",
       "0  7607.132915     na  19401.653846  \n",
       "1  1141.952450     na  14791.000000  \n",
       "2  4256.375378     na  14544.000000  \n",
       "3  2800.490677     na   2800.000000  \n",
       "4   689.582605     na  15478.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the simulated data and holidays data\n",
    "dt_simulated_weekly = pd.read_csv(\"resources/dt_simulated_weekly.csv\")\n",
    "\n",
    "print(\"Simulated Data...\")\n",
    "dt_simulated_weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182efb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holidays Data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>holiday</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-06</td>\n",
       "      <td>Epiphany</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-28</td>\n",
       "      <td>Carnival</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-14</td>\n",
       "      <td>Constitution Day</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-14</td>\n",
       "      <td>Good Friday</td>\n",
       "      <td>AD</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ds           holiday country  year\n",
       "0  1995-01-01    New Year's Day      AD  1995\n",
       "1  1995-01-06          Epiphany      AD  1995\n",
       "2  1995-02-28          Carnival      AD  1995\n",
       "3  1995-03-14  Constitution Day      AD  1995\n",
       "4  1995-04-14       Good Friday      AD  1995"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_prophet_holidays = pd.read_csv(\"resources/dt_prophet_holidays.csv\")\n",
    "\n",
    "print(\"Holidays Data...\")\n",
    "dt_prophet_holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cce14",
   "metadata": {},
   "source": [
    "## 2.2. Initialize Robyn\n",
    "\n",
    "Now, let's initialize Robyn with our synthetic data and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a272787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:24:53,226 - root - INFO - Robyn initialized with working directory: ~/temp/robyn\n",
      "2024-11-14 18:24:53,228 - robyn.data.validation.mmmdata_validation - INFO - Starting complete MMMData validation\n",
      "2024-11-14 18:24:53,229 - robyn.data.validation.mmmdata_validation - INFO - Missing and infinite value check passed successfully\n",
      "2024-11-14 18:24:53,231 - robyn.data.validation.mmmdata_validation - INFO - No-variance check passed successfully\n",
      "2024-11-14 18:24:53,231 - robyn.data.validation.mmmdata_validation - INFO - Variable names validation passed successfully\n",
      "2024-11-14 18:24:53,234 - robyn.data.validation.mmmdata_validation - INFO - Date variable validation passed successfully\n",
      "2024-11-14 18:24:53,234 - robyn.data.validation.mmmdata_validation - INFO - Dependent variable validation passed successfully\n",
      "2024-11-14 18:24:53,234 - robyn.data.validation.mmmdata_validation - INFO - All validations passed successfully\n",
      "2024-11-14 18:24:53,235 - robyn.data.validation.holidays_data_validation - INFO - Starting complete validation process\n",
      "2024-11-14 18:24:53,242 - robyn.data.validation.holidays_data_validation - INFO - Holidays validation completed. Status: True\n",
      "2024-11-14 18:24:53,245 - robyn.data.validation.holidays_data_validation - INFO - Prophet validation completed. Status: True\n",
      "2024-11-14 18:24:53,245 - robyn.data.validation.holidays_data_validation - INFO - Validation complete. Overall status: True\n",
      "2024-11-14 18:24:53,245 - robyn.data.validation.hyperparameter_validation - INFO - Starting validation process\n",
      "2024-11-14 18:24:53,246 - robyn.data.validation.hyperparameter_validation - INFO - Starting hyperparameters validation\n",
      "2024-11-14 18:24:53,246 - robyn.data.validation.hyperparameter_validation - INFO - Hyperparameter validation completed. Status: True\n",
      "2024-11-14 18:24:53,246 - robyn.data.validation.hyperparameter_validation - INFO - Validation completed with status: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation complete\n",
      "Robyn initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Robyn\n",
    "robyn = Robyn(working_dir=\"~/temp/robyn\")\n",
    "\n",
    "# Create MMMData\n",
    "mmm_data_spec = MMMData.MMMDataSpec(\n",
    "    dep_var=\"revenue\",\n",
    "    dep_var_type=\"revenue\",\n",
    "    date_var=\"DATE\",\n",
    "    context_vars=[\"competitor_sales_B\", \"events\"],\n",
    "    paid_media_spends=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_S\", \"search_S\"],\n",
    "    paid_media_vars=[\"tv_S\", \"ooh_S\", \"print_S\", \"facebook_I\", \"search_clicks_P\"],\n",
    "    organic_vars=[\"newsletter\"],\n",
    "    window_start=\"2016-01-01\",\n",
    "    window_end=\"2018-12-31\",\n",
    ")\n",
    "\n",
    "mmm_data = MMMData(data=dt_simulated_weekly, mmmdata_spec=mmm_data_spec)\n",
    "\n",
    "# Create HolidaysData (using dummy data for demonstration)\n",
    "holidays_data = HolidaysData(\n",
    "    dt_holidays=dt_prophet_holidays,\n",
    "    prophet_vars=[\"trend\", \"season\", \"holiday\"],\n",
    "    prophet_country=\"DE\",\n",
    "    prophet_signs=[\"default\", \"default\", \"default\"],\n",
    ")\n",
    "\n",
    "# Create Hyperparameters\n",
    "hyperparameters = Hyperparameters(\n",
    "    {\n",
    "        \"facebook_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"print_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"tv_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.3, 0.8],\n",
    "        ),\n",
    "        \"search_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0, 0.3],\n",
    "        ),\n",
    "        \"ooh_S\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "        \"newsletter\": ChannelHyperparameters(\n",
    "            alphas=[0.5, 3],\n",
    "            gammas=[0.3, 1],\n",
    "            thetas=[0.1, 0.4],\n",
    "        ),\n",
    "    },\n",
    "    adstock=AdstockType.GEOMETRIC,\n",
    "    lambda_=[0, 1],\n",
    "    train_size=[0.5, 0.8],\n",
    ")\n",
    "\n",
    "\n",
    "## Calibration is not supported yet\n",
    "# Create CalibrationInput (using dummy data for demonstration)\n",
    "# calibration_input = CalibrationInput({\n",
    "#     \"tv_spend\": ChannelCalibrationData(\n",
    "#         lift_start_date=pd.Timestamp(\"2022-03-01\"),\n",
    "#         lift_end_date=pd.Timestamp(\"2022-03-15\"),\n",
    "#         lift_abs=10000,\n",
    "#         spend=50000,\n",
    "#         confidence=0.9,\n",
    "#         metric=\"revenue\",\n",
    "#         calibration_scope=CalibrationScope.IMMEDIATE\n",
    "#     )\n",
    "# })\n",
    "\n",
    "# Initialize Robyn\n",
    "robyn.initialize(\n",
    "    mmm_data=mmm_data,\n",
    "    holidays_data=holidays_data,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "print(\"Robyn initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836832f",
   "metadata": {},
   "source": [
    "## 3. Run Robyn Model\n",
    "\n",
    "After initialization, we can run the Robyn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cc2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:24:53,252 - robyn.modeling.feature_engineering - INFO - Starting feature engineering process\n",
      "2024-11-14 18:24:53,254 - robyn.modeling.feature_engineering - INFO - Starting Prophet decomposition\n",
      "2024-11-14 18:24:53,255 - robyn.modeling.feature_engineering - INFO - Starting Prophet decomposition\n",
      "/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/prophet/forecaster.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.holidays['ds'] = pd.to_datetime(self.holidays['ds'])\n",
      "2024-11-14 18:24:53,903 - cmdstanpy - DEBUG - input tempfile: /var/folders/gm/g5cpl7110m96nfd1qr1xwnwc0000gn/T/tmpwyr5bsxb/1e5qgege.json\n",
      "2024-11-14 18:24:53,914 - cmdstanpy - DEBUG - input tempfile: /var/folders/gm/g5cpl7110m96nfd1qr1xwnwc0000gn/T/tmpwyr5bsxb/w5uurkhu.json\n",
      "2024-11-14 18:24:53,915 - cmdstanpy - DEBUG - idx 0\n",
      "2024-11-14 18:24:53,916 - cmdstanpy - DEBUG - running CmdStan, num_threads: None\n",
      "2024-11-14 18:24:53,916 - cmdstanpy - DEBUG - CmdStan args: ['/Users/yijuilee/robynpy_release_reviews/robynvenv/lib/python3.9/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84719', 'data', 'file=/var/folders/gm/g5cpl7110m96nfd1qr1xwnwc0000gn/T/tmpwyr5bsxb/1e5qgege.json', 'init=/var/folders/gm/g5cpl7110m96nfd1qr1xwnwc0000gn/T/tmpwyr5bsxb/w5uurkhu.json', 'output', 'file=/var/folders/gm/g5cpl7110m96nfd1qr1xwnwc0000gn/T/tmpwyr5bsxb/prophet_modelltu9rqbm/prophet_model-20241114182453.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "18:24:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2024-11-14 18:24:53,916 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:24:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2024-11-14 18:24:54,065 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2024-11-14 18:24:54,158 - robyn.modeling.feature_engineering - INFO - Prophet decomposition complete\n",
      "2024-11-14 18:24:54,161 - robyn.modeling.feature_engineering - INFO - Starting model runs for paid media variables with different exposure metrics\n",
      "2024-11-14 18:24:54,162 - robyn.modeling.feature_engineering - INFO - Fitting spend-exposure model for facebook_I\n",
      "2024-11-14 18:24:54,174 - robyn.modeling.feature_engineering - INFO - Fitting spend-exposure model for search_clicks_P\n",
      "2024-11-14 18:24:54,186 - robyn.modeling.feature_engineering - INFO - Completed model runs for 2 channels\n",
      "2024-11-14 18:24:54,187 - robyn.modeling.feature_engineering - INFO - Feature engineering complete\n",
      "2024-11-14 18:24:54,189 - robyn.modeling.feature_engineering - INFO - Filled 0 missing values\n",
      "2024-11-14 18:24:54,190 - robyn.modeling.base_model_executor - INFO - Initializing BaseModelExecutor\n",
      "2024-11-14 18:24:54,190 - robyn.modeling.model_executor - INFO - Starting model execution with model_name=Models.RIDGE\n",
      "2024-11-14 18:24:54,190 - robyn.modeling.base_model_executor - INFO - Input validation successful\n",
      "2024-11-14 18:24:54,191 - robyn.modeling.base_model_executor - INFO - Preparing hyperparameters\n",
      "2024-11-14 18:24:54,191 - robyn.modeling.base_model_executor - INFO - Completed hyperparameter preparation with 20 parameters to optimize\n",
      "2024-11-14 18:24:54,191 - robyn.modeling.model_executor - INFO - Initializing Ridge model builder\n",
      "2024-11-14 18:24:54,191 - robyn.modeling.model_executor - INFO - Building models with configured parameters\n",
      "2024-11-14 18:24:54,192 - robyn.modeling.ridge_model_builder - INFO - Collecting hyperparameters for optimization...\n",
      "Running trial 1 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 18:24:59,806 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.09 mins\n",
      "Running trial 2 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 18:25:05,470 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.09 mins\n",
      "Running trial 3 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 18:25:11,045 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.09 mins\n",
      "Running trial 4 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 18:25:16,403 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.09 mins\n",
      "Running trial 5 of total 5 trials: 100%|███████████████████████████████████\n",
      "2024-11-14 18:25:21,803 - robyn.modeling.ridge_model_builder - INFO -  Finished in 0.09 mins\n",
      "2024-11-14 18:25:21,809 - robyn.visualization.model_convergence_visualizer - INFO - Initialized ModelConvergenceVisualizer\n",
      "2024-11-14 18:25:21,810 - robyn.modeling.convergence.convergence - INFO - Starting convergence calculation\n",
      "2024-11-14 18:25:21,811 - robyn.modeling.convergence.convergence - WARNING - 'mape' column not found or all zeros. Assuming model is not calibrated.\n",
      "2024-11-14 18:25:21,822 - robyn.modeling.convergence.convergence - WARNING - Convergence status for DECOMP.RSSD: NOT converged\n",
      "2024-11-14 18:25:21,822 - robyn.modeling.convergence.convergence - INFO - DECOMP.RSSD NOT converged: sd@qt.20 0.078 > 0.064 & |med@qt.20| 0.35 > 0.26\n",
      "2024-11-14 18:25:21,823 - robyn.modeling.convergence.convergence - WARNING - Convergence status for NRMSE: NOT converged\n",
      "2024-11-14 18:25:21,823 - robyn.modeling.convergence.convergence - INFO - NRMSE NOT converged: sd@qt.20 0.021 <= 0.036 & |med@qt.20| 0.30 > 0.22\n",
      "2024-11-14 18:25:21,824 - robyn.modeling.convergence.convergence - INFO - Creating visualization plots\n",
      "2024-11-14 18:25:21,840 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-14 18:25:21,843 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-14 18:25:21,845 - matplotlib.category - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2024-11-14 18:25:22,178 - robyn.visualization.model_convergence_visualizer - INFO - Successfully created moo distribution plot\n",
      "2024-11-14 18:25:22,525 - robyn.visualization.model_convergence_visualizer - INFO - Successfully created moo cloud plot\n",
      "2024-11-14 18:25:22,727 - robyn.visualization.model_convergence_visualizer - INFO - Successfully created time-series validation plot\n",
      "2024-11-14 18:25:22,908 - robyn.modeling.convergence.convergence - INFO - Convergence calculation completed successfully\n",
      "2024-11-14 18:25:22,911 - robyn.modeling.model_executor - INFO - Model building completed successfully\n",
      "2024-11-14 18:25:22,911 - robyn.modeling.model_executor - INFO - Model execution completed successfully\n",
      "2024-11-14 18:25:22 [INFO] Starting Pareto optimization\n",
      "2024-11-14 18:25:22 [INFO] Starting model data aggregation\n",
      "2024-11-14 18:25:22 [INFO] Computing Pareto fronts\n",
      "2024-11-14 18:25:22 [INFO] Pareto front computation completed\n",
      "2024-11-14 18:25:22 [INFO] Preparing Pareto data\n",
      "2024-11-14 18:25:22 [INFO] Number of Pareto-optimal solutions found: 222\n",
      "2024-11-14 18:25:22 [INFO] Selected 10 Pareto-fronts containing 110 candidates\n",
      "2024-11-14 18:25:22 [INFO] Filtering data for selected Pareto fronts...\n",
      "2024-11-14 18:25:22 [INFO] Calculating response curves for 550 models' media variables...\n",
      "Processing rows: 100%|██████████| 550/550 [00:05<00:00, 96.22it/s] \n",
      "2024-11-14 18:25:29 [INFO] Successfully processed 550 response curves\n",
      "2024-11-14 18:25:29 [INFO] Computing final metrics...\n",
      "2024-11-14 18:25:29 [INFO] Calculating ROI and CPA metrics...\n",
      "2024-11-14 18:25:29 [INFO] Starting plot data generation...\n",
      "2024-11-14 18:25:29 [INFO] Processing Pareto front 1\n",
      "2024-11-14 18:25:29 [INFO] Pareto-Front: 1 [5 models]\n",
      "Processing Solutions:   0%|          | 0/5 [00:00<?, ?solution/s]2024-11-14 18:25:29 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:29 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  40%|████      | 2/5 [00:00<00:00, 10.86solution/s]2024-11-14 18:25:29 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  80%|████████  | 4/5 [00:00<00:00, 11.03solution/s]2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 5/5 [00:00<00:00, 10.90solution/s]\n",
      "2024-11-14 18:25:30 [INFO] Processing Pareto front 2\n",
      "2024-11-14 18:25:30 [INFO] Pareto-Front: 2 [6 models]\n",
      "Processing Solutions:   0%|          | 0/6 [00:00<?, ?solution/s]2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  33%|███▎      | 2/6 [00:00<00:00,  8.20solution/s]2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  67%|██████▋   | 4/6 [00:00<00:00,  9.51solution/s]2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 6/6 [00:00<00:00,  9.85solution/s]\n",
      "2024-11-14 18:25:30 [INFO] Processing Pareto front 3\n",
      "2024-11-14 18:25:30 [INFO] Pareto-Front: 3 [10 models]\n",
      "Processing Solutions:   0%|          | 0/10 [00:00<?, ?solution/s]2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:30 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  20%|██        | 2/10 [00:00<00:00, 10.99solution/s]2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  40%|████      | 4/10 [00:00<00:00, 10.37solution/s]2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  60%|██████    | 6/10 [00:00<00:00, 10.72solution/s]2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  80%|████████  | 8/10 [00:00<00:00, 10.94solution/s]2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 10/10 [00:00<00:00, 10.92solution/s]\n",
      "2024-11-14 18:25:31 [INFO] Processing Pareto front 4\n",
      "2024-11-14 18:25:31 [INFO] Pareto-Front: 4 [10 models]\n",
      "Processing Solutions:   0%|          | 0/10 [00:00<?, ?solution/s]2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  20%|██        | 2/10 [00:00<00:00, 10.85solution/s]2024-11-14 18:25:31 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  40%|████      | 4/10 [00:00<00:00, 11.37solution/s]2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  60%|██████    | 6/10 [00:00<00:00, 11.33solution/s]2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  80%|████████  | 8/10 [00:00<00:00, 11.28solution/s]2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 10/10 [00:00<00:00, 11.27solution/s]\n",
      "2024-11-14 18:25:32 [INFO] Processing Pareto front 5\n",
      "2024-11-14 18:25:32 [INFO] Pareto-Front: 5 [11 models]\n",
      "Processing Solutions:   0%|          | 0/11 [00:00<?, ?solution/s]2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  18%|█▊        | 2/11 [00:00<00:00, 11.05solution/s]2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:32 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  36%|███▋      | 4/11 [00:00<00:00, 11.25solution/s]2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  55%|█████▍    | 6/11 [00:00<00:00, 11.13solution/s]2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  73%|███████▎  | 8/11 [00:00<00:00, 11.14solution/s]2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  91%|█████████ | 10/11 [00:00<00:00, 11.09solution/s]2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 11/11 [00:00<00:00, 11.12solution/s]\n",
      "2024-11-14 18:25:33 [INFO] Processing Pareto front 6\n",
      "2024-11-14 18:25:33 [INFO] Pareto-Front: 6 [13 models]\n",
      "Processing Solutions:   0%|          | 0/13 [00:00<?, ?solution/s]2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  15%|█▌        | 2/13 [00:00<00:00, 11.01solution/s]2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:33 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  31%|███       | 4/13 [00:00<00:00, 11.16solution/s]2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  46%|████▌     | 6/13 [00:00<00:00, 11.03solution/s]2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  62%|██████▏   | 8/13 [00:00<00:00, 11.05solution/s]2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  77%|███████▋  | 10/13 [00:00<00:00, 11.05solution/s]2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  92%|█████████▏| 12/13 [00:01<00:00, 11.11solution/s]2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 13/13 [00:01<00:00, 11.08solution/s]\n",
      "2024-11-14 18:25:34 [INFO] Processing Pareto front 7\n",
      "2024-11-14 18:25:34 [INFO] Pareto-Front: 7 [13 models]\n",
      "Processing Solutions:   0%|          | 0/13 [00:00<?, ?solution/s]2024-11-14 18:25:34 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:   8%|▊         | 1/13 [00:00<00:02,  5.30solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  15%|█▌        | 2/13 [00:00<00:01,  6.74solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  23%|██▎       | 3/13 [00:00<00:01,  7.51solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  38%|███▊      | 5/13 [00:00<00:00,  9.28solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  54%|█████▍    | 7/13 [00:00<00:00, 10.04solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  69%|██████▉   | 9/13 [00:00<00:00, 10.51solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  85%|████████▍ | 11/13 [00:01<00:00, 10.81solution/s]2024-11-14 18:25:35 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 13/13 [00:01<00:00,  9.72solution/s]\n",
      "2024-11-14 18:25:36 [INFO] Processing Pareto front 8\n",
      "2024-11-14 18:25:36 [INFO] Pareto-Front: 8 [16 models]\n",
      "Processing Solutions:   0%|          | 0/16 [00:00<?, ?solution/s]2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  12%|█▎        | 2/16 [00:00<00:01, 10.85solution/s]2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  25%|██▌       | 4/16 [00:00<00:01, 11.08solution/s]2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  38%|███▊      | 6/16 [00:00<00:00, 11.12solution/s]2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  50%|█████     | 8/16 [00:00<00:00,  9.78solution/s]2024-11-14 18:25:36 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  62%|██████▎   | 10/16 [00:00<00:00, 10.20solution/s]2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  75%|███████▌  | 12/16 [00:01<00:00, 10.44solution/s]2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  88%|████████▊ | 14/16 [00:01<00:00, 10.63solution/s]2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 16/16 [00:01<00:00, 10.62solution/s]\n",
      "2024-11-14 18:25:37 [INFO] Processing Pareto front 9\n",
      "2024-11-14 18:25:37 [INFO] Pareto-Front: 9 [14 models]\n",
      "Processing Solutions:   0%|          | 0/14 [00:00<?, ?solution/s]2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  14%|█▍        | 2/14 [00:00<00:01, 10.89solution/s]2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:37 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  29%|██▊       | 4/14 [00:00<00:00, 10.98solution/s]2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  43%|████▎     | 6/14 [00:00<00:00, 10.91solution/s]2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  57%|█████▋    | 8/14 [00:00<00:00, 10.91solution/s]2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  71%|███████▏  | 10/14 [00:00<00:00, 10.95solution/s]2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  86%|████████▌ | 12/14 [00:01<00:00, 10.84solution/s]2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:38 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 14/14 [00:01<00:00, 10.72solution/s]\n",
      "2024-11-14 18:25:38 [INFO] Processing Pareto front 10\n",
      "2024-11-14 18:25:38 [INFO] Pareto-Front: 10 [12 models]\n",
      "Processing Solutions:   0%|          | 0/12 [00:00<?, ?solution/s]2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  17%|█▋        | 2/12 [00:00<00:00, 10.51solution/s]2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  33%|███▎      | 4/12 [00:00<00:00, 10.75solution/s]2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  50%|█████     | 6/12 [00:00<00:00, 10.92solution/s]2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  67%|██████▋   | 8/12 [00:00<00:00, 10.78solution/s]2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions:  83%|████████▎ | 10/12 [00:00<00:00, 10.82solution/s]2024-11-14 18:25:39 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "2024-11-14 18:25:40 [INFO] Calculating saturated dataframes with carryover and immediate parts\n",
      "Processing Solutions: 100%|██████████| 12/12 [00:01<00:00, 10.77solution/s]\n",
      "2024-11-14 18:25:40 [INFO] Pareto optimization completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation complete.\n",
      "Model training and evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "from robyn.modeling.entities.modelrun_trials_config import TrialsConfig\n",
    "\n",
    "\n",
    "trials_config = TrialsConfig(iterations=54, trials=5)\n",
    "\n",
    "# Run the model\n",
    "robyn.model_e2e_run(plot=False, trials_config=trials_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede6c0d",
   "metadata": {},
   "source": [
    "## 4. Budget Allocation\n",
    "\n",
    "Finally, let's perform budget allocation using the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e98ff",
   "metadata": {},
   "source": [
    "This notebook demonstrates the basic workflow of using Robyn for Marketing Mix Modeling. In a real-world scenario, you would need to replace the synthetic data with your actual marketing data and adjust the parameters accordingly.\n",
    "\n",
    "Remember to explore the full capabilities of Robyn, including model evaluation, visualization, and interpretation of results, which are beyond the scope of this basic demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2859a6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 18:25:40,103 - robyn.allocator.budget_allocator - INFO - Initializing BudgetAllocator\n",
      "2024-11-14 18:25:40,105 - robyn.allocator.media_response - INFO - Initializing MediaResponseParamsCalculator\n",
      "2024-11-14 18:25:40,105 - robyn.allocator.allocation_optimizer - INFO - Initializing AllocationOptimizer\n",
      "2024-11-14 18:25:40,106 - robyn.allocator.media_response - INFO - Starting media response parameters calculation for model 2_1_1\n",
      "2024-11-14 18:25:40,110 - robyn.allocator.media_response - INFO - Successfully calculated media response parameters: MediaResponseParameters(alphas=5 channels, inflexions=5 channels, coefficients=5 channels)\n",
      "2024-11-14 18:25:40,111 - robyn.allocator.budget_allocator - INFO - BudgetAllocator initialization completed successfully\n",
      "2024-11-14 18:25:40,111 - robyn.allocator.budget_allocator - INFO - Starting budget allocation optimization\n",
      "2024-11-14 18:25:40,113 - robyn.allocator.budget_allocator - WARNING - Found zero mean spend for channels: ['tv_S' 'ooh_S' 'print_S' 'search_S']\n",
      "2024-11-14 18:25:40,114 - robyn.allocator.response_calculator - INFO - Successfully calculated gradient value: -0.0000\n",
      "2024-11-14 18:25:40,114 - robyn.allocator.response_calculator - INFO - Successfully calculated gradient value: -0.0000\n",
      "2024-11-14 18:25:40,114 - robyn.allocator.response_calculator - INFO - Successfully calculated gradient value: -0.0000\n",
      "2024-11-14 18:25:40,115 - robyn.allocator.response_calculator - INFO - Successfully calculated gradient value: -0.0000\n",
      "2024-11-14 18:25:40,115 - robyn.allocator.response_calculator - INFO - Successfully calculated gradient value: -0.0000\n",
      "2024-11-14 18:25:40,115 - robyn.allocator.budget_allocator - INFO - Initial metrics calculated successfully\n",
      "2024-11-14 18:25:40,115 - robyn.allocator.budget_allocator - INFO - Running optimization for scenario: OptimizationScenario.MAX_RESPONSE\n",
      "2024-11-14 18:25:40,116 - robyn.allocator.budget_allocator - INFO - Starting maximum response optimization\n",
      "2024-11-14 18:25:40,116 - robyn.allocator.allocation_optimizer - INFO - Starting optimization with method: SLSQP_AUGLAG\n",
      "2024-11-14 18:25:40,117 - robyn.allocator.allocation_optimizer - INFO - Running optimization\n",
      "2024-11-14 18:25:40,118 - robyn.allocator.allocation_optimizer - INFO - Optimization completed successfully\n",
      "2024-11-14 18:25:40,118 - robyn.allocator.budget_allocator - INFO - Maximum response optimization completed successfully\n",
      "2024-11-14 18:25:40,136 - robyn.allocator.budget_allocator - INFO - Response curves generated successfully\n",
      "2024-11-14 18:25:40,149 - robyn.allocator.budget_allocator - INFO - Response curves generated successfully\n",
      "2024-11-14 18:25:40,150 - robyn.allocator.budget_allocator - INFO - Budget allocation optimization completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Model ID: 2_1_1\n",
      "            Scenario: max_response\n",
      "            Use case: \n",
      "            Window: 2019-11-11 00:00:00:2019-11-11 00:00:00 (1 week)\n",
      "            Dep. Variable Type: revenue\n",
      "            Media Skipped: None\n",
      "            Relative Spend Increase: 0.0% (+0K)\n",
      "            Total Response Increase (Optimized): 0.0%\n",
      "            Allocation Summary:\n",
      "            \n",
      "\n",
      "                - tv_S:\n",
      "                  Optimizable bound: [-30%, 20%],\n",
      "                  Initial spend share: 7.14% -> Optimized bounded: 7.14%\n",
      "                  Initial response share: 9.90% -> Optimized bounded: 9.90%\n",
      "                  Initial abs. mean spend: 1.221K -> Optimized: 1.221K [Delta = 0%]\n",
      "                \n",
      "\n",
      "                - ooh_S:\n",
      "                  Optimizable bound: [-30%, 50%],\n",
      "                  Initial spend share: 7.14% -> Optimized bounded: 7.14%\n",
      "                  Initial response share: 0.00% -> Optimized bounded: 0.00%\n",
      "                  Initial abs. mean spend: 1.221K -> Optimized: 1.221K [Delta = 0%]\n",
      "                \n",
      "\n",
      "                - print_S:\n",
      "                  Optimizable bound: [-30%, 50%],\n",
      "                  Initial spend share: 7.14% -> Optimized bounded: 7.14%\n",
      "                  Initial response share: 0.37% -> Optimized bounded: 0.37%\n",
      "                  Initial abs. mean spend: 1.221K -> Optimized: 1.221K [Delta = 0%]\n",
      "                \n",
      "\n",
      "                - facebook_S:\n",
      "                  Optimizable bound: [-30%, 50%],\n",
      "                  Initial spend share: 71.43% -> Optimized bounded: 71.43%\n",
      "                  Initial response share: 80.26% -> Optimized bounded: 80.26%\n",
      "                  Initial abs. mean spend: 12.206K -> Optimized: 12.206K [Delta = 0%]\n",
      "                \n",
      "\n",
      "                - search_S:\n",
      "                  Optimizable bound: [-30%, 50%],\n",
      "                  Initial spend share: 7.14% -> Optimized bounded: 7.14%\n",
      "                  Initial response share: 9.46% -> Optimized bounded: 9.46%\n",
      "                  Initial abs. mean spend: 1.221K -> Optimized: 1.221K [Delta = 0%]\n",
      "                \n",
      "AllocationResult(\n",
      "Total Current Spend: $17,088.90\n",
      "Total Optimal Spend: $17,088.90\n",
      "Spend Lift: +0.0%\n",
      "Response Lift: +0.0%)\n"
     ]
    }
   ],
   "source": [
    "from robyn.allocator.entities.allocation_constraints import AllocationConstraints\n",
    "from robyn.allocator.entities.allocation_config import AllocationConfig\n",
    "from robyn.allocator.entities.enums import OptimizationScenario, ConstrMode\n",
    "\n",
    "# Define allocation constraints\n",
    "channel_constraints = AllocationConstraints(\n",
    "    channel_constr_low={\n",
    "        \"tv_S\": 0.7,  # -30% from base\n",
    "        \"ooh_S\": 0.7,\n",
    "        \"print_S\": 0.7,\n",
    "        \"facebook_S\": 0.7,\n",
    "        \"search_S\": 0.7,\n",
    "    },\n",
    "    channel_constr_up={\n",
    "        \"tv_S\": 1.2,  # +20% from base\n",
    "        \"ooh_S\": 1.5,  # +50% from base\n",
    "        \"print_S\": 1.5,\n",
    "        \"facebook_S\": 1.5,\n",
    "        \"search_S\": 1.5,\n",
    "    },\n",
    "    channel_constr_multiplier=3.0,\n",
    ")\n",
    "# Configure allocation scenario\n",
    "allocation_config = AllocationConfig(\n",
    "    scenario=OptimizationScenario.MAX_RESPONSE,\n",
    "    constraints=channel_constraints,\n",
    "    date_range=\"last\",  # Use last period as initial\n",
    "    total_budget=None,  # Use historical budget\n",
    "    maxeval=100000,\n",
    "    optim_algo=\"SLSQP_AUGLAG\",\n",
    "    constr_mode=ConstrMode.EQUALITY,\n",
    ")\n",
    "\n",
    "# Call the budget_allocator method\n",
    "allocation_result = robyn.budget_allocator(\n",
    "    select_model=None,  # Replace with your actual model ID\n",
    "    allocation_constraints=channel_constraints,\n",
    "    allocator_config=allocation_config,\n",
    "    plot=False,\n",
    "    export=False,\n",
    ")\n",
    "# Display the allocation result\n",
    "print(allocation_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
